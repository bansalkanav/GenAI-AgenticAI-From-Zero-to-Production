{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d233ed9-8279-494a-b519-8f862d7087c4",
   "metadata": {},
   "source": [
    "# **Embedding**\n",
    "\n",
    "Embeddings convert text into numeric vectors (lists of numbers) that capture semantic meaning, enabling AI systems to understand and compare text based on meaning rather than exact word matches.\n",
    "\n",
    "## **What Are Embeddings?**\n",
    "An embedding is a vector (array of numbers) that represents the semantic meaning of text. Instead of storing text as strings, we store it as numbers that a machine learning model can understand and compare.\n",
    "```python\n",
    "# Text\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# After embedding (example - not real values)\n",
    "embedding = [0.234, -0.456, 0.789, 0.123, ..., 0.567]  # 1536 dimensions (for OpenAI)\n",
    "```\n",
    "\n",
    "## **Text Embedding Models**\n",
    "The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.\n",
    "\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "The base Embeddings class in LangChain provides two methods: \n",
    "1. For embedding documents - while the latter takes a single text\n",
    "2. For embedding a query -  takes as input multiple texts\n",
    "\n",
    "The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290b1d7-e32c-4179-961d-feb0b042cadd",
   "metadata": {},
   "source": [
    "## **Initialize OpenAIEmbeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27c5038-fbae-4314-9c1f-45da12a5446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_langchain/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY, \n",
    "                                    model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa780ef-e228-4fc3-9fe6-42e23234e746",
   "metadata": {},
   "source": [
    "## **Embed Single Query - `embed_query`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5a384e-4791-450e-81dc-1f3e3c2cd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of embedded vector: 3072\n",
      "\n",
      "[0.005890291649848223, 0.041957274079322815, -0.026762796565890312, 0.007915631867945194, -0.030353575944900513, 0.005187171045690775, 0.012921495363116264, -0.011126106604933739, 0.009251118637621403, 0.024321774020791054, 0.0004958325298503041, 0.038313429802656174, -0.008198649622499943, 0.038030412048101425, 0.029681408777832985]\n"
     ]
    }
   ],
   "source": [
    "# Embed single query\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Dimensionality of embedded vector:\", len(embedded_query))\n",
    "print()\n",
    "print(embedded_query[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b33d1-0546-4409-9f5f-9f42c5eff919",
   "metadata": {},
   "source": [
    "### **Embed list of Texts - `embed_documents`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c9dd7a-ff7f-4dd8-9d43-3fadbdf01569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 5\n",
      "Dimensionality of Embeddings: 3072\n"
     ]
    }
   ],
   "source": [
    "# Embed list of texts\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "                                [\n",
    "                                    \"Hi there!\",\n",
    "                                    \"Oh, hello!\",\n",
    "                                    \"What's your name?\",\n",
    "                                    \"My friends call me World\",\n",
    "                                    \"Hello World!\"\n",
    "                                ]\n",
    ")\n",
    "\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n",
    "\n",
    "print(\"Dimensionality of Embeddings:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272a886-fed3-4e10-a12c-c3d87a759dcf",
   "metadata": {},
   "source": [
    "### **Create Embeddings for Subtitles Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91baca3-d78e-41e7-b66d-3bed23fb0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 6523.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all .srt files\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('data/subtitles', glob=\"*.srt\", show_progress=True, loader_cls=TextLoader)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009e7572-8273-472d-a68a-161b165f3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))\n",
    "\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee609559-bf85-4f95-9041-de6ac71b1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:01,435 --> 00:00:04,082\n",
      "This is pretty much\n",
      "what's happened so far.\n",
      "\n",
      "2\n",
      "00:00:04,395 --> 00:0\n"
     ]
    }
   ],
   "source": [
    "# To read 0th document, we can use .page_content\n",
    "\n",
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d11663f-e9f5-4d1d-9a53-e8a713c36874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reading the content of all the .srt files\n",
    "\n",
    "# [srt_file.page_content for srt_file in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9597e1d-f715-4388-b376-7c38196ef22e",
   "metadata": {},
   "source": [
    "**Important Note: Be careful running the following code. It will encounter some `cost`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0bb30b-62ce-4391-bc69-f7dfc5e3835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating embeddings for all the 23 .srt files\n",
    "\n",
    "# embedded_docs = embeddings_model.embed_documents([srt_file.page_content for srt_file in docs])\n",
    "\n",
    "# print(\"Type of variable:\", type(embedded_docs))\n",
    "\n",
    "# print(\"Number of embeddings:\", len(embedded_docs))\n",
    "\n",
    "# print(\"Dimensionality of each embedding:\", len(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b122f79-f9b9-40b9-a591-53c6177efc1d",
   "metadata": {},
   "source": [
    "## **HuggingFace Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e8d1137-00d1-4e28-9394-dd776977058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers\n",
    "# ! pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eed315d-9166-42b8-85d5-7b1c5f7cd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d313924e-4c8b-42bd-ad95-5f00583e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = embeddings_model.embed_documents([\n",
    "                    \"Hi there!\",\n",
    "                    \"Oh, hello!\",\n",
    "                    \"What's your name?\",\n",
    "                    \"My friends call me World\",\n",
    "                    \"Hello World!\"\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f05c09-1f75-42c3-b2b6-bfc3460db8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of variable: <class 'list'>\n",
      "Number of embeddings: 5\n",
      "Dimensionality of each embedding: 768\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of variable:\", type(embedded_docs))\n",
    "\n",
    "print(\"Number of embeddings:\", len(embedded_docs))\n",
    "\n",
    "print(\"Dimensionality of each embedding:\", len(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c680065-2bda-44d5-b5a2-693aea293367",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "We just learned how to take documents and embed them into vectors.\n",
    "\n",
    "These vectors are stored in memory as a Python list. Whenever we restart the program, these Python lists will flush out.\n",
    "\n",
    "How do we make sure these embeddings persist to some permanent storage?\n",
    "\n",
    "**Important Note: If generating embeddings has cost associated with it, why to generate it every time? Why not store these embeddings in a database during the first execution and use these embeddings from the database from next time onwards for better cost management.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
