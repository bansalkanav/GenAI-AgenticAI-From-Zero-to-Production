{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d233ed9-8279-494a-b519-8f862d7087c4",
   "metadata": {},
   "source": [
    "# **Embeddings**\n",
    "\n",
    "## **What's Covered?**\n",
    "1. Introduction to Embeddings\n",
    "    - What Are Embeddings?\n",
    "    - Text Embedding Models\n",
    "    - Top LangChain Integrations\n",
    "2. Generating Embeddings via API using GoogleGenAI and OpenAI\n",
    "    - Installing the libraries\n",
    "    - Setting up the API Key\n",
    "    - Instantiating the Embedding Models\n",
    "    - Embed Single Query using embed_query()\n",
    "    - Embed list of Documents using embed_documents()\n",
    "3. Generating Embeddings Locally using HuggingFaceEmbeddings\n",
    "    - Installing the libraries\n",
    "    - Instantiating the Embedding Models\n",
    "    - Embed Single Query using embed_query()\n",
    "    - Embed list of Documents using embed_documents()\n",
    "4. End-to-End Embedding Pipeline\n",
    "    - Step 1: Load the documents\n",
    "    - Step 2: Apply Chunking\n",
    "    - Step 3: Convert the Chunks into Embeddings\n",
    "5. What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae7479-1e40-4460-935a-75b4135862e6",
   "metadata": {},
   "source": [
    "## **Introduction to Embeddings**\n",
    "Embeddings convert text into numeric vectors (lists of numbers) that capture semantic meaning, enabling AI systems to understand and compare text based on meaning rather than exact word matches.\n",
    "\n",
    "### **What Are Embeddings?**\n",
    "An embedding is a vector (array of numbers) that represents the semantic meaning of text. Instead of storing text as strings, we store it as numbers that a machine learning model can understand and compare.\n",
    "```python\n",
    "# Text\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# After embedding (example - not real values)\n",
    "embedding = [0.234, -0.456, 0.789, 0.123, ..., 0.567]  # 1536 dimensions (for OpenAI)\n",
    "```\n",
    "\n",
    "### **Text Embedding Models**\n",
    "The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.\n",
    "\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "### **Top LangChain Integrations**\n",
    "\n",
    "| Model                          | Package                   |\n",
    "|--------------------------------|----------------------------|\n",
    "| OpenAIEmbeddings               | langchain-openai           |\n",
    "| AzureOpenAIEmbeddings          | langchain-openai           |\n",
    "| GoogleGenerativeAIEmbeddings   | langchain-google-genai     |\n",
    "| OllamaEmbeddings               | langchain-ollama           |\n",
    "| TogetherEmbeddings             | langchain-together         |\n",
    "| FireworksEmbeddings            | langchain-fireworks        |\n",
    "| MistralAIEmbeddings            | langchain-mistralai        |\n",
    "| CohereEmbeddings               | langchain-cohere           |\n",
    "| NomicEmbeddings                | langchain-nomic            |\n",
    "| FakeEmbeddings                 | langchain-core             |\n",
    "| DatabricksEmbeddings           | databricks-langchain       |\n",
    "| WatsonxEmbeddings              | langchain-ibm              |\n",
    "| NVIDIAEmbeddings               | langchain-nvidia           |\n",
    "| AimlapiEmbeddings              | langchain-aimlapi          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe0782-8fc4-48e7-8034-269cfce33621",
   "metadata": {},
   "source": [
    "## **Generating Embeddings via API using GoogleGenAI and OpenAI**\n",
    "\n",
    "### **Installing the libraries**\n",
    "\n",
    "```python\n",
    "! pip install --upgrade --quiet langchain-google-genai\n",
    "! pip install --upgrade --quiet langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85e2671e-9d78-4feb-8f51-49470bda05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade --quiet langchain-google-genai\n",
    "# ! pip install --upgrade --quiet langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3ca03-e432-4bb3-a5ce-260428afb061",
   "metadata": {},
   "source": [
    "### **Setting up the API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4be136-5a17-47a1-bbd4-abe6356fbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.gemini.txt')\n",
    "\n",
    "GOOGLE_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef5bf37-92e3-4507-bae9-a9928bfea34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290b1d7-e32c-4179-961d-feb0b042cadd",
   "metadata": {},
   "source": [
    "### **Instantiating the Embedding Models**\n",
    "\n",
    "The base Embeddings class in **LangChain provides two methods**: \n",
    "1. **For embedding documents** - while the latter takes a single text\n",
    "2. **For embedding a query** -  takes as input multiple texts\n",
    "\n",
    "The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b146d6cc-9dd8-4f9a-80ab-5f4251ffb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Embedding Models\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Pass the standard parameters during initialization\n",
    "google_embd_model = GoogleGenerativeAIEmbeddings(google_api_key=GOOGLE_API_KEY, \n",
    "                                                 model=\"models/gemini-embedding-001\")\n",
    "\n",
    "openai_embd_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, \n",
    "                                     model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa780ef-e228-4fc3-9fe6-42e23234e746",
   "metadata": {},
   "source": [
    "### **Embed Single Query using `embed_query()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d5a384e-4791-450e-81dc-1f3e3c2cd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of embedded vector: 3072\n",
      "\n",
      "[-0.030619625002145767, 0.0032838324550539255, 0.0156903937458992, -0.08700630068778992, -0.008714504539966583, 0.004057515878230333, -0.011523551307618618, 0.006958039943128824, -0.022802716121077538, 0.010272241197526455, -0.006420494522899389, -0.007641482166945934, -0.0015980988973751664, 0.007948610931634903, 0.11037036031484604]\n"
     ]
    }
   ],
   "source": [
    "# Embed single query\n",
    "\n",
    "embedded_query = google_embd_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Dimensionality of embedded vector:\", len(embedded_query))\n",
    "print()\n",
    "print(embedded_query[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c69d93d-f090-4bc2-bed2-66a821fff267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of embedded vector: 1536\n",
      "\n",
      "[-0.010680568404495716, -0.01018487848341465, -0.0019450020045042038, 0.023096051067113876, -0.02682921662926674, 0.013724414631724358, -0.03931440785527229, 0.04200971871614456, -0.009875072166323662, -0.07416760176420212, 0.016946399584412575, -0.038973618298769, -0.02641097828745842, -0.043775614351034164, -0.013639218173921108]\n"
     ]
    }
   ],
   "source": [
    "# Embed single query\n",
    "\n",
    "embedded_query = openai_embd_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Dimensionality of embedded vector:\", len(embedded_query))\n",
    "print()\n",
    "print(embedded_query[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b33d1-0546-4409-9f5f-9f42c5eff919",
   "metadata": {},
   "source": [
    "### **Embed list of Documents using `embed_documents()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "526da411-8485-4a57-87e7-feeeec1c9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Hi there!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me World\",\n",
    "    \"Hello World!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c9dd7a-ff7f-4dd8-9d43-3fadbdf01569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 5\n",
      "Dimensionality of Embeddings: 3072\n"
     ]
    }
   ],
   "source": [
    "# Embed list of docs\n",
    "\n",
    "embeddings = google_embd_model.embed_documents(docs)\n",
    "\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n",
    "\n",
    "print(\"Dimensionality of Embeddings:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e846cdd-b1e4-4103-8a29-0943492e88bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 5\n",
      "Dimensionality of Embeddings: 1536\n"
     ]
    }
   ],
   "source": [
    "# Embed list of docs\n",
    "\n",
    "embeddings = openai_embd_model.embed_documents(docs)\n",
    "\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n",
    "\n",
    "print(\"Dimensionality of Embeddings:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b122f79-f9b9-40b9-a591-53c6177efc1d",
   "metadata": {},
   "source": [
    "## **Generating Embeddings Locally using HuggingFaceEmbeddings**\n",
    "\n",
    "### **Installing the libraries**\n",
    "```python\n",
    "! pip install sentence-transformers\n",
    "! pip install langchain-huggingface\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e8d1137-00d1-4e28-9394-dd776977058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers\n",
    "# ! pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19095006-aa64-442b-8b9d-140e2880d77c",
   "metadata": {},
   "source": [
    "### **Instantiating the Embedding Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eed315d-9166-42b8-85d5-7b1c5f7cd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "hf_embd_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f434bb-661c-44e7-bb95-527d73e891df",
   "metadata": {},
   "source": [
    "### **Embed Single Query using embed_query()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5705c82-cad7-4300-b405-2a85efec8a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of embedded vector: 768\n",
      "\n",
      "[0.09514585137367249, 9.883820894174278e-05, -0.016573389992117882, 0.04484795406460762, 0.043236978352069855, -0.008534776046872139, 0.08940394222736359, 0.002871787641197443, -0.031132318079471588, 0.052375730127096176, -0.0026622936129570007, -0.00033354779588989913, 0.023539021611213684, -0.09407063573598862, -0.014772295951843262]\n"
     ]
    }
   ],
   "source": [
    "embedded_query = hf_embd_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Dimensionality of embedded vector:\", len(embedded_query))\n",
    "print()\n",
    "print(embedded_query[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c8eb4-0a33-4d53-8c4c-8969e07a7bd1",
   "metadata": {},
   "source": [
    "### **Embed list of Documents using embed_documents()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "202feefa-298b-4231-ad27-fead10eefba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Hi there!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me World\",\n",
    "    \"Hello World!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d313924e-4c8b-42bd-ad95-5f00583e2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 5\n",
      "Dimensionality of Embeddings: 768\n"
     ]
    }
   ],
   "source": [
    "embeddings = hf_embd_model.embed_documents(docs)\n",
    "\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n",
    "\n",
    "print(\"Dimensionality of Embeddings:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272a886-fed3-4e10-a12c-c3d87a759dcf",
   "metadata": {},
   "source": [
    "## **End-to-End Embedding Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83433beb-8818-4ffd-854d-4981657e8ab1",
   "metadata": {},
   "source": [
    "### **Step 1: Load the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91baca3-d78e-41e7-b66d-3bed23fb0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 6523.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all .srt files\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('data/subtitles', glob=\"*.srt\", show_progress=True, loader_cls=TextLoader)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009e7572-8273-472d-a68a-161b165f3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))\n",
    "\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee609559-bf85-4f95-9041-de6ac71b1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:01,435 --> 00:00:04,082\n",
      "This is pretty much\n",
      "what's happened so far.\n",
      "\n",
      "2\n",
      "00:00:04,395 --> 00:0\n"
     ]
    }
   ],
   "source": [
    "# To read 0th document, we can use .page_content\n",
    "\n",
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d11663f-e9f5-4d1d-9a53-e8a713c36874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reading the content of all the .srt files\n",
    "\n",
    "# [srt_file.page_content for srt_file in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba92e2b-1777-4b6f-88f7-dbedc211a607",
   "metadata": {},
   "source": [
    "### **Step 2: Apply Chunking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d590c-f0ae-4219-8ea2-19ae659e431e",
   "metadata": {},
   "source": [
    "### **Step 3: Convert the Chunks into Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9597e1d-f715-4388-b376-7c38196ef22e",
   "metadata": {},
   "source": [
    "**Important Note: Be careful running the following code. It will encounter some `cost`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0bb30b-62ce-4391-bc69-f7dfc5e3835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating embeddings for all the 23 .srt files\n",
    "\n",
    "# embedded_docs = embeddings_model.embed_documents([srt_file.page_content for srt_file in docs])\n",
    "\n",
    "# print(\"Type of variable:\", type(embedded_docs))\n",
    "\n",
    "# print(\"Number of embeddings:\", len(embedded_docs))\n",
    "\n",
    "# print(\"Dimensionality of each embedding:\", len(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c680065-2bda-44d5-b5a2-693aea293367",
   "metadata": {},
   "source": [
    "## **What's next?**\n",
    "\n",
    "We just learned how to take documents and embed them into vectors.\n",
    "\n",
    "These vectors are **stored in memory as a Python list**. Whenever we **restart the program**, these Python lists will flush out.\n",
    "\n",
    "How do we make sure these embeddings persist to some permanent storage?\n",
    "\n",
    "**Important Note: If generating embeddings has cost associated with it, why to generate it every time? Why not store these embeddings in a database during the first execution and use these embeddings from the database from next time onwards for better cost management.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
