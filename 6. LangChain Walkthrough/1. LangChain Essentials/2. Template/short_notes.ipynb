{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d72449-69e1-4dab-9b68-4ab9c60551cf",
   "metadata": {},
   "source": [
    "# **Templates - Making Prompts Dynamic and Reusable**\n",
    "1. PromptTemplate\n",
    "- Creating a PromptTemplate\n",
    "- Passing Placeholder Values to PromptTemplate\n",
    "- Convert StringPromptValue to String/Messages\n",
    "- Types of Templates - System, Human and AI\n",
    "- Types of Concrete Messages - System, Human and AI\n",
    "2. ChatPromptTemplate\n",
    "- Creating a ChatPromptTemplate\n",
    "- Passing Placeholder Values to ChatPromptTemplate\n",
    "- Convert ChatPromptValue to String/Messages\n",
    "- MessagePlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34e66d6-dfd3-423c-902b-3c209cfdc357",
   "metadata": {},
   "source": [
    "## **Prompt Template**\n",
    "\n",
    "### **Creating a PromptTemplate**\n",
    "1. Using .from_template()\n",
    "2. Using direct init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a4ea579-1bb5-4d03-bb1b-d42499feefd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], input_types={}, partial_variables={}, template='Tell me a {adjective} joke about {content}.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Using .from_template()\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "# Usig direct init\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2473ab3-81c6-48a6-93c8-9686d2c260df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective', 'content']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014864e-4e19-48d6-b7da-d7d7e1a809bc",
   "metadata": {},
   "source": [
    "### **Passing Placeholder Values to Prompt Template**\n",
    "1. Using .format()\n",
    "2. Using .format_prompt()\n",
    "3. Using .invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b78e57fd-d393-4512-afd2-0e8dde543dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about genai.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a string\n",
    "prompt_template.format(adjective=\"funny\", content=\"genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0bb621a-40a7-4790-8b4f-f4ef67e8763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a funny joke about genai.')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a StringPromptValue\n",
    "prompt_template.format_prompt(adjective=\"funny\", content=\"genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5743f1d8-f54d-4de2-b40b-44ea54a510e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a funny joke about genai.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a StringPromptValue\n",
    "prompt_template.invoke({\"adjective\":\"funny\", \"content\":\"genai\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ab90e-1ea1-45bb-b2ee-1b5c15b9cfe9",
   "metadata": {},
   "source": [
    "### **Convert StringPromptValue to String or List of Messages**\n",
    "1. .to_string()\n",
    "2. .to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "828bf9ea-6317-4982-9e48-088ebc10fdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about genai.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spv = prompt_template_2.invoke({\"adjective\":\"funny\", \"content\":\"genai\"})\n",
    "\n",
    "spv.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d65191be-88a5-4153-870e-cdf5fdfd5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me a funny joke about genai.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spv.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc29391-cb55-49e5-9ab0-ca163449d820",
   "metadata": {},
   "source": [
    "### **Passing Partial Variables in PromptTemplate**\n",
    "1. Passing Partial Variable while creating the Prompt Template Object - Using partial_variable argument\n",
    "2. Passing Partial Variable in an existing template - Using .partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a57ad59-4797-4ad4-8256-24582fce9862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\",\n",
    "    partial_variables={\"adjective\": \"funny\"}\n",
    ")\n",
    "\n",
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee2a2dc0-af6a-4f8f-8ef1-6a2f2a583540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt_template_pv = prompt_template.partial(adjective=\"funny\")\n",
    "\n",
    "prompt_template_pv.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06cd83-b353-4d72-8b32-c61df600919f",
   "metadata": {},
   "source": [
    "### **Types of Templates**\n",
    "\n",
    "These are classes that represent templates for specific types of messages (System, Human, AI). They define the structure and content of a message, often including placeholders ({variable_name}) that need to be filled in later. Example:\n",
    "- SystemMessagePromptTemplate\n",
    "- HumanMessagePromptTemplate\n",
    "- AIMessagePromptTemplate\n",
    "\n",
    "They are not directly sent to the LLM. They first need to be \"formatted\" or \"invoked\" to produce concrete `*Message` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d021019-4f76-489d-9ac8-c8e47dee6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='You are a helpful assistant specialized in {topic}.'), additional_kwargs={})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful assistant specialized in {topic}.\"\n",
    ")\n",
    "\n",
    "system_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5d57739-972f-40f6-92e0-ef0133ddb018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['concept'], input_types={}, partial_variables={'user_name': 'ThatAIGuy'}, template='My name is {user_name}. Can you explain {concept}?'), additional_kwargs={})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"My name is {user_name}. Can you explain {concept}?\", \n",
    "    partial_variables={\"user_name\":\"ThatAIGuy\"}\n",
    ")\n",
    "\n",
    "human_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23ec7989-73d1-45cd-87a6-eb74ba29b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='My name is Alice.'), additional_kwargs={})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import AIMessagePromptTemplate\n",
    "\n",
    "ai_template = AIMessagePromptTemplate.from_template(\n",
    "    \"My name is Alice.\"\n",
    ")\n",
    "\n",
    "ai_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0000e6-be8a-44e6-9cc0-dc99ddb1f52d",
   "metadata": {},
   "source": [
    "### **Types of Concrete Messages**\n",
    "\n",
    "These are actual, concrete message objects that contain the final, filled-in text content and their respective roles (system, human, AI). They represent a single turn or instruction in a conversation. Example:\n",
    "- SystemMessage\n",
    "- HumanMessage\n",
    "- AIMessage\n",
    "\n",
    "They are the \"data\" that the LLM processes.\n",
    "\n",
    "**They do not contain placeholders ({}). Their content is fully resolved.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb23706d-6540-4a22-b589-2099162621a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='You are a polite and friendly chatbot.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_instruction = SystemMessage(content=\"You are a polite and friendly chatbot.\")\n",
    "\n",
    "system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd2b05ec-2d41-4634-b4d6-69e614b3edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='What is the weather like today?', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "user_query = HumanMessage(content=\"What is the weather like today?\")\n",
    "\n",
    "user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9023ca85-8593-445d-9e5d-d85457f4c49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I don't have access to real-time weather information.\", additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "ai_response = AIMessage(content=\"I'm sorry, I don't have access to real-time weather information.\")\n",
    "\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f569df-f33a-496c-b481-241f12934213",
   "metadata": {},
   "source": [
    "## **ChatPromptTemplate**\n",
    "\n",
    "### **Creating a ChatPromptTemplate**\n",
    "1. Using .from_template()\n",
    "2. Using .from_messages()\n",
    "3. Using direct init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd965c3f-1aec-42b2-807a-9019ad1703f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['bot_name', 'topic_name'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['bot_name'], input_types={}, partial_variables={}, template='You are a helpful AI bot. Your name is {bot_name}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, how are you doing?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"I'm doing well, thanks!\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic_name'], input_types={}, partial_variables={}, template='Tell me about {topic_name}.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Using .from_template()\n",
    "chat_template = ChatPromptTemplate.from_template(\n",
    "    \"Tell me about {topic_name}?\"\n",
    ")\n",
    "\n",
    "# Using .from_messages()\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {bot_name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"Tell me about {topic_name}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Using direct init\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {bot_name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"Tell me about {topic_name}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19985a65-c67e-49a6-a986-ea2f6e8a4506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bot_name', 'topic_name']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a3a80c9-9399-49cd-847f-299826b6dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Option A: Using message objects explicitly\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a helpful AI bot. Your name is {bot_name}.\", \n",
    "                                                  partial_variables={\"bot_name\": \"ThatAIGuy\"}),\n",
    "        HumanMessage(content=\"Hello, how are you doing?\"),\n",
    "        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Tell me about {topic_name}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# chat_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c813e7-46da-430f-939f-a4520338ef40",
   "metadata": {},
   "source": [
    "### **Passing Placeholder Values to ChatPromptTemplate**\n",
    "1. Using .format()\n",
    "2. Using .format_prompt()\n",
    "3. Using .format_messages()\n",
    "4. Using .invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a02acef-0daf-4c2b-946e-3b966158a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI bot. Your name is Alice.\\nHuman: Hello, how are you doing?\\nAI: I'm doing well, thanks!\\nHuman: Tell me about langchain.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a string\n",
    "\n",
    "chat_template_3.format(bot_name=\"Alice\", topic_name=\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ffda99-d652-477b-b8c1-1ede5803d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a ChatPromptValue\n",
    "\n",
    "chat_template_3.format_prompt(bot_name=\"Alice\", topic_name=\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021924f9-4125-4964-9220-992a0a325819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a List of messages\n",
    "\n",
    "chat_template_3.format_messages(bot_name=\"Alice\", topic_name=\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "751f0ad8-e2ed-447c-bfc2-bc9724375ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Note: This returns a ChatPromptValue\n",
    "\n",
    "chat_template_3.invoke({\"bot_name\":\"Alice\", \"topic_name\":\"langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbd0a2-e10f-4f63-abf4-4b434d383464",
   "metadata": {},
   "source": [
    "### **Convert ChatPromptValue to String or List of Messages**\n",
    "1. .to_string()\n",
    "2. .to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f787130a-1be0-4624-bff0-121533944064",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpv = chat_template_3.invoke({\"bot_name\":\"Alice\", \"topic_name\":\"langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd2f1c7-4a78-4b25-b486-bae3d377b14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI bot. Your name is Alice.\\nHuman: Hello, how are you doing?\\nAI: I'm doing well, thanks!\\nHuman: Tell me about langchain.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpv.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8a352ae-eb08-4867-8927-57fa29dc8d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpv.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e21fa-50a7-497b-8236-60d25113def2",
   "metadata": {},
   "source": [
    "### **Passing Partial Variables in ChatPromptTemplate**\n",
    "1. Passing Partial Variable while creating the ChatPromptTemplate Object - Using partial_variable argument\n",
    "2. Passing Partial Variable in an existing template - Using .partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d815f35-e415-4817-8852-08b569a60849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_name']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {bot_name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"Tell me about {topic_name}.\"),\n",
    "    ],\n",
    "    partial_variables={\"bot_name\": \"Alice\"}\n",
    ")\n",
    "\n",
    "chat_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e29a2f7-6e07-4ede-bbfa-31ab15c5fc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.invoke({\"topic_name\": \"langchain\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e55386d-c192-4ee3-9e0e-67e75413ea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_name']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {bot_name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"Tell me about {topic_name}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template_pv = chat_template.partial(bot_name=\"Tim\")\n",
    "\n",
    "chat_template_pv.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63d55bed-815a-4c80-b708-0a2e21eafa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Tim.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Tell me about langchain.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template_pv.invoke({\"topic_name\": \"langchain\"}).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b402ed-a751-4c12-bd61-77ce6ff6d23a",
   "metadata": {},
   "source": [
    "### **MessagesPlaceholder**\n",
    "\n",
    "At its core, `MessagesPlaceholder` is a special type of \"placeholder\" within a `ChatPromptTemplate` that is designed to accept a sequence of messages (like HumanMessage, AIMessage, SystemMessage).\n",
    "\n",
    "\n",
    "#### **How it Works?**  \n",
    "When you include MessagesPlaceholder in your ChatPromptTemplate.from_messages() or ChatPromptTemplate() definition:\n",
    "1. You give it a variable_name (e.g., \"chat_history\").\n",
    "2. When you invoke() the ChatPromptTemplate (or a chain containing it), you must pass a key in your input dictionary that matches this variable_name. The value for this key must be a list of BaseMessage objects.\n",
    "3. LangChain then takes this list of messages and inserts them directly into the position specified by MessagesPlaceholder within the final list of messages sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30018c4f-3478-4abe-aab5-0b6275b215a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Simulate some pre-existing chat history\n",
    "current_chat_history = [\n",
    "    HumanMessage(content=\"What's your favorite color?\"),\n",
    "    AIMessage(content=\"As an AI, I don't have feelings or preferences, so I don't have a favorite color.\"),\n",
    "    HumanMessage(content=\"Oh, I see. What's your favorite animal then?\"),\n",
    "    AIMessage(content=\"Similarly, I don't have personal experiences to develop preferences for animals.\"),\n",
    "]\n",
    "\n",
    "# Simulate some pre-existing chat history\n",
    "current_chat_history = [\n",
    "    (\"human\", \"What's your favorite color?\"),\n",
    "    (\"ai\", \"As an AI, I don't have feelings or preferences, so I don't have a favorite color.\"),\n",
    "    (\"human\", \"Oh, I see. What's your favorite animal then?\"),\n",
    "    (\"ai\", \"Similarly, I don't have personal experiences to develop preferences for animals.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b95efab8-2fb6-43f6-8f6e-cc667ce10b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful and knowledgeable assistant.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{new_question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "\n",
    "# Define a ChatPromptTemplate that includes MessagesPlaceholder\n",
    "chat_prompt_with_history = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a helpful and knowledgeable assistant.\"),\n",
    "        # This is where the magic happens: insert the chat history\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        # The new human message for the current turn\n",
    "        HumanMessagePromptTemplate.from_template(\"{new_question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_prompt_with_history.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd59f7f1-b7a6-493f-9a3e-1c256a67ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: Input to ChatPromptTemplate is missing variables {'chat_history'}.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chat_prompt_with_history.invoke({\"new_question\": \"Can you summarize our conversation so far?\"})\n",
    "except:\n",
    "    print(\"KeyError: Input to ChatPromptTemplate is missing variables {'chat_history'}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e7f52d3-1b67-4d73-877d-04215398e503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful and knowledgeable assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's your favorite color?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"As an AI, I don't have feelings or preferences, so I don't have a favorite color.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Oh, I see. What's your favorite animal then?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Similarly, I don't have personal experiences to develop preferences for animals.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Can you summarize our conversation so far?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_messages = chat_prompt_with_history.invoke({\"new_question\": \"Can you summarize our conversation so far?\", \n",
    "                                 \"chat_history\": current_chat_history})\n",
    "formatted_messages.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6cb5f1e5-dda4-48fc-bb20-f95668c647ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful and knowledgeable assistant.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's your favorite color?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI, I don't have feelings or preferences, so I don't have a favorite color.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Oh, I see. What's your favorite animal then?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Similarly, I don't have personal experiences to develop preferences for animals.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you summarize our conversation so far?\n"
     ]
    }
   ],
   "source": [
    "for msg in formatted_messages.to_messages():\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e520e08-3bb8-452c-b8df-658e7e055dda",
   "metadata": {},
   "source": [
    "#### **Making MessagesPlaceholder Optional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9156618-7fd3-44bd-a26f-ae542b8eb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful and knowledgeable assistant.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{new_question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define a ChatPromptTemplate that includes MessagesPlaceholder\n",
    "chat_prompt_with_history = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful and knowledgeable assistant.\"),\n",
    "        # This is where the magic happens: insert the chat history\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        # The new human message for the current turn\n",
    "        HumanMessagePromptTemplate.from_template(\"{new_question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_prompt_with_history.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacaa79-4f39-47c3-85fb-b4732177be3c",
   "metadata": {},
   "source": [
    "#### **Limiting the number of messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e384deac-bcf1-42fd-b4ff-dccc79fa7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful and knowledgeable assistant.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Oh, I see. What's your favorite animal then?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Similarly, I don't have personal experiences to develop preferences for animals.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you summarize our conversation so far?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Simulate some pre-existing chat history\n",
    "current_chat_history = [\n",
    "    HumanMessage(content=\"What's your favorite color?\"),\n",
    "    AIMessage(content=\"As an AI, I don't have feelings or preferences, so I don't have a favorite color.\"),\n",
    "    HumanMessage(content=\"Oh, I see. What's your favorite animal then?\"),\n",
    "    AIMessage(content=\"Similarly, I don't have personal experiences to develop preferences for animals.\"),\n",
    "]\n",
    "\n",
    "# Define a ChatPromptTemplate that includes MessagesPlaceholder\n",
    "chat_prompt_with_history = ChatPromptTemplate(\n",
    "    messages = [ SystemMessage(content=\"You are a helpful and knowledgeable assistant.\"),\n",
    "                # This is where the magic happens: insert the chat history\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\", optional=True, n_messages=2),\n",
    "                # The new human message for the current turn\n",
    "                HumanMessagePromptTemplate.from_template(\"{new_question}\"),\n",
    "                ] \n",
    ")\n",
    "\n",
    "formatted_messages = chat_prompt_with_history.invoke({\n",
    "    \"chat_history\": current_chat_history,\n",
    "    \"new_question\": \"Can you summarize our conversation so far?\"\n",
    "})\n",
    "\n",
    "for msg in formatted_messages.to_messages():\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f65c6-690f-4072-b109-a428173da504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
