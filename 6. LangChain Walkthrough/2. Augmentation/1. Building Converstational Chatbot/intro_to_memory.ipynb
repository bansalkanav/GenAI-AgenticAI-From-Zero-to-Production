{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5c86a2-76b6-4cf7-8f94-051684e7784d",
   "metadata": {},
   "source": [
    "# **Memory**\n",
    "\n",
    "## **What's covered?**\n",
    "1. What is Memory?\n",
    "2. Building Memory into a system\n",
    "3. Depricated Classes\n",
    "4. Buidling End-to-end Conversational AI Bot by designing Memory from Scratch\n",
    "    - Step 1: Import Chat Model and Configure the API Key\n",
    "    - Step 2: Create Chat Template\n",
    "    - Step 3: Create a Output Parser\n",
    "    - Step 4: Initialize the Memory\n",
    "    - Step 5: Build a Chain\n",
    "    - Step 6: Invoke the chain\n",
    "    - Step 7: Saving to memory\n",
    "    - Step 8: Run Step 6 and 7 in a loop\n",
    "5. Saving a Chat History to a Pickle File\n",
    "6. Loading a Chat History from a Pickle File\n",
    "7. Manage Message History with SQLChatMessageHistory and Adding Session ID\n",
    "\n",
    "## **What is Memory?**\n",
    "Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users' preferences. \n",
    "\n",
    "Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation. At bare minimum, a conversational system should be able to access some window of past messages directly. A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships.\n",
    "\n",
    "We call this ability to store information about past interactions \"memory\". \n",
    "\n",
    "## **Building memory into a system**\n",
    "The two core design decisions in any memory system are:\n",
    "- How state is stored\n",
    "- How state is queried\n",
    "\n",
    "## **Depricated Classes**\n",
    "- ConversationBufferMemory\n",
    "- ConversationStringBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- ConversationSummaryMemory\n",
    "- ConversationSummaryBufferMemory\n",
    "- VectorStoreRetrieverMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210d13f-efab-42cd-bfa9-3d04865048bb",
   "metadata": {},
   "source": [
    "## **Buidling End-to-end Conversational AI Bot by designing Memory from Scratch**\n",
    "\n",
    "### **Steps:**\n",
    "1. Import Chat Model and Configure the API Key\n",
    "2. Create Chat Template\n",
    "3. Create a Output Parser\n",
    "4. Initialize the Memory\n",
    "5. Build a Chain\n",
    "6. Invoke the chain with human_input and chat_history\n",
    "7. Saving to memory\n",
    "8. Run Step 6 and 7 in a loop\n",
    "\n",
    "<img src=\"images/memory.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aad706-9487-46f0-9549-862a8844400c",
   "metadata": {},
   "source": [
    "### **Step 1: Import Chat Model and Configure the API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c109071-82b9-4628-a1eb-a0fcfe7588bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Import Chat Model and Configure the API Key\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35146a15-059e-4285-98c8-e3e3d6860521",
   "metadata": {},
   "source": [
    "### **Step 2: Create Chat Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d991c8dd-ddb9-47b0-b483-ede46666e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Create Chat Template\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages = [\n",
    "        # The persistent system prompt\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # Creating a chat_history placeholder\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  \n",
    "        # Human Prompt\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005c9fd-d846-4e9d-8260-50fca0ccea11",
   "metadata": {},
   "source": [
    "### **Step 3: Create a Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5795c6-04cc-42dd-a874-29a2ab0fc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Create a Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd491e7-4254-4ae0-ae07-fbd913006663",
   "metadata": {},
   "source": [
    "### **Step 4: Initialize the Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70898aed-44e4-49cf-bd30-bf6832f4abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Initialize the Memory\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "memory_buffer = {\"history\": []}\n",
    "\n",
    "def get_history_from_buffer(human_input):\n",
    "    return memory_buffer[\"history\"]\n",
    "\n",
    "runnable_get_history_from_buffer = RunnableLambda(get_history_from_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d6c9f-caff-42db-8cda-1d51864ad344",
   "metadata": {},
   "source": [
    "#### **RunnablePassthrough:** RunnablePassthrough on its own allows you to pass inputs unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0db275-974a-409d-af73-7a103a0a6413",
   "metadata": {},
   "source": [
    "### **Step 5: Build a Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6db02f-49ab-4ae3-af8d-810604ed99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Build a Chain (Another way)\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define a chain\n",
    "chain = RunnablePassthrough.assign(\n",
    "        chat_history=runnable_get_history_from_buffer\n",
    "        ) | chat_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd263bab-9a2d-46d7-8099-e0f4c4fa7a0d",
   "metadata": {},
   "source": [
    "### **Step 6: Invoke the chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dce5bc2-84d8-4c46-b8ac-48a2e82040f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 - Invoke the chain with human_input and chat_history\n",
    "\n",
    "query = {\"human_input\": \"Hi, How are you?\"}\n",
    "\n",
    "response = chain.invoke(query)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189a3dbc-59a7-4c4b-8038-2ddbc4ac5353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086b6bd-bbf3-4d79-b875-054554fb77ba",
   "metadata": {},
   "source": [
    "### **Step 7: Saving to memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f4b47a-9190-4f3d-82b6-d1b0f585a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7 - Saving to memory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "memory_buffer[\"history\"].append(HumanMessage(content=query[\"human_input\"]))\n",
    "memory_buffer[\"history\"].append(AIMessage(content=response))\n",
    "\n",
    "memory_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbb567-5ea7-4192-b677-6ee259c6e819",
   "metadata": {},
   "source": [
    "### **Step 8 - Run Step 6 and 7 in a loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de61677b-9f1f-4e23-a100-eb279342f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  My name is Kanav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: My name is Kanav\n",
      "*AI: Hello Kanav! It's nice to meet you. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  just exploring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: just exploring\n",
      "*AI: That's great! Feel free to ask me anything or share any topics you'd like to explore. I'm here to help and provide information.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  that's good to know\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: that's good to know\n",
      "*AI: I'm glad to hear that! If you have any questions or need assistance, don't hesitate to ask. I'm here to help.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  what;s my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: what;s my name?\n",
      "*AI: Your name is Kanav.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: exit\n"
     ]
    }
   ],
   "source": [
    "# Step 8 - Run Step 6 and 7 in a loop\n",
    "\n",
    "while True:\n",
    "    query = {\"human_input\" : input('Enter your input: ')}\n",
    "    print(f\"*User: {query['human_input']}\")\n",
    "    if query[\"human_input\"] in ['bye', 'quit', 'exit']:\n",
    "        break\n",
    "    response = chain.invoke(query)\n",
    "    print(f\"*AI: {response}\")\n",
    "\n",
    "    memory_buffer[\"history\"].append(HumanMessage(content=query[\"human_input\"]))\n",
    "    memory_buffer[\"history\"].append(AIMessage(content=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc450acb-d899-4180-9a39-e480de710128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, How are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='My name is Kanav', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello Kanav! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='just exploring', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's great! Feel free to ask me anything or share any topics you'd like to explore. I'm here to help and provide information.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"that's good to know\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm glad to hear that! If you have any questions or need assistance, don't hesitate to ask. I'm here to help.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what;s my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Kanav.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_buffer[\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fd022-9da2-4d0b-9581-cf8363f36097",
   "metadata": {},
   "source": [
    "## **Saving a Chat History to a Pickle File**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f57c5-b8f5-4efc-a409-bf4e221629d4",
   "metadata": {},
   "source": [
    "**Let's now learn to save this history on the disk so that whenever we can load the history whenever we chat with our assistant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8217df9c-fcd3-4f4d-baa2-85e413e7e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "chat_history = pickle.dumps(memory_buffer)\n",
    "\n",
    "with open(\"chats_data/conversation_memory.pkl\", \"wb\") as f:\n",
    "    f.write(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5c8b1-4521-43ce-83f2-f1c84d3609d0",
   "metadata": {},
   "source": [
    "## **Loading a Chat History from a Pickle File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ca65b7-c292-45f2-92e4-20f84679277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_loaded = pickle.load(open(\"chats_data/conversation_memory.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fb23db-84d4-45cf-82a9-1e46184fba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Kanav', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello Kanav! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='just exploring', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great! Feel free to ask me anything or share any topics you'd like to explore. I'm here to help and provide information.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"that's good to know\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm glad to hear that! If you have any questions or need assistance, don't hesitate to ask. I'm here to help.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what;s my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Kanav.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57196c-f3b8-49d3-b812-8c4d999e6adf",
   "metadata": {},
   "source": [
    "## **Manage Message History with SQLChatMessageHistory and Adding Session ID**\n",
    "\n",
    "`ChatMessageHistory` allows us to store separate conversation histories per user or session which is often done by the real-time chatbots. `session_id` is used to distinguish between separate conversations.\n",
    "\n",
    "In order to use it, we can use a `get_session_history` function which take `session_id` and returns a message history object.\n",
    "\n",
    "There is a support of many `Memory` components under `langchain_community.chat_message_histories`, like:\n",
    "1. AstraDBChatMessageHistory\n",
    "2. DynamoDBChatMessageHistory\n",
    "3. CassandraChatMessageHistory\n",
    "4. ElasticsearchChatMessageHistory\n",
    "5. KafkaChatMessageHistory\n",
    "6. MongoDBChatMessageHistory\n",
    "7. RedisChatMessageHistory\n",
    "8. PostgresChatMessageHistory\n",
    "9. SQLChatMessageHistory\n",
    "\n",
    "**[Click Here](https://python.langchain.com/docs/integrations/memory/)** to read more.\n",
    "\n",
    "### **Usage**\n",
    "\n",
    "To use the storage you need to provide only 2 things:\n",
    "\n",
    "1. **Session Id** - a unique identifier of the session, like user name, email, chat id etc.\n",
    "2. **Connection string**\n",
    "    - For SQL (SQLAlchemy) - A string that specifies the database connection. It will be passed to SQLAlchemy create_engine function.\n",
    "    - For SQLite - A string that specifies the database connection. For SQLite, that string is slqlite:/// followed by the name of the database file. If that file doesn't exist, it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8041c5-7d00-4cf6-a9fc-71c9c03f2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain-community SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def066d9-117f-481a-942a-69d0dd8d483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8de1ed9-082b-40ce-bb96-69dc61022146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73fcc4a9-2e7a-4f83-bc25-4c95d573ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection with the database and \n",
    "# return the chat message history for a session id\n",
    "\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "def get_session_message_history_from_db(session_id):\n",
    "    chat_message_history = SQLChatMessageHistory(\n",
    "                                   session_id=session_id, \n",
    "                                   connection=\"sqlite:///chats_data/sqlite.db\"\n",
    "                               )\n",
    "    return chat_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5043c4-3fa1-484f-beae-937766b8741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "                messages=[\n",
    "                    (\"system\", \"You are a helpful AI assistant.\"), \n",
    "                    MessagesPlaceholder(variable_name=\"history\"), \n",
    "                    (\"human\", \"{human_input}\")\n",
    "                ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3bac9b-9370-4a60-8fad-23b175e1065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the chain\n",
    "\n",
    "chain = chat_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989e9909-67fc-4afa-a369-ef0e231b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RunnableWithMessageHistory to load \n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "conversation_chain = RunnableWithMessageHistory(\n",
    "                        chain, \n",
    "                        get_session_message_history_from_db,\n",
    "                        input_messages_key=\"human_input\", \n",
    "                        history_messages_key=\"history\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e00998b-2fe4-4ada-a48c-7da04c4da47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the capital of Himachal Pradesh is Shimla.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we configure the session id\n",
    "user_id = \"thataiguy\"\n",
    "config = {\"configurable\": {\"session_id\": user_id}}\n",
    "\n",
    "input_prompt = {\"human_input\": \"My name is ThatAIGuy. Can you tell me the capital of Himachal?\"}\n",
    "response = conversation_chain.invoke(input_prompt, config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361e0eaa-bd4d-4617-94be-ba5a2e0311a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The biggest state in India is Rajasthan.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we configure the session id\n",
    "user_id = \"kanav\"\n",
    "config = {\"configurable\": {\"session_id\": user_id}}\n",
    "\n",
    "input_prompt = {\"human_input\": \"My name is Kanav Bansal. What is the biggest state in India?\"}\n",
    "response = conversation_chain.invoke(input_prompt, config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815f32f8-c0ec-4cd8-a52a-80e9adda6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot(session_id, prompt):\n",
    "    config = {\"configurable\": {\"session_id\": user_id}}\n",
    "    input_prompt = {\"human_input\": prompt}\n",
    "\n",
    "    response = conversation_chain.invoke(input_prompt, config=config)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c27159-25a8-43bd-ad05-6a8bba6f91a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, your name is ThatAIGuy.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = \"thataiguy\"\n",
    "input_prompt = \"Do you remember my name?\"\n",
    "chat_bot(session_id=user_id, prompt=input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8122a47-96a9-4afd-a328-7e28909594b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, your name is Kanav Bansal.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = \"kanav\"\n",
    "input_prompt = \"Do you remember my name?\"\n",
    "chat_bot(session_id=user_id, prompt=input_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
