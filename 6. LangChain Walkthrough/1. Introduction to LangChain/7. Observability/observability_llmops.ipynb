{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10030f5-4435-42cb-9233-09ff7517c318",
   "metadata": {},
   "source": [
    "# **Introduction to LangSmith**\n",
    "\n",
    "## **What is LangSmith?**\n",
    "Provides observability & evaluation which helps to debug, test and monitor AI systems/workflows. Eg: Identify why your production workflow is taking more time (i.e. latency), measure the cost, token usage, hallucination, etc...\n",
    "\n",
    "## **What is Observability?**\n",
    "Ability to understand a system's internal state by analyzing its external outputs, primarily through telemetry data (i.e. logs, metrics and traces)\n",
    "- **Logs:** Chronological records of events, actions and messages from the system\n",
    "- **Metrics:** Numerical measurement over time eg: CPU usage, number of requests, latency, etc...\n",
    "- **Traces:** Records the journey of a single request as it moves across different services in a distributed system, showing timing and flow.\n",
    "\n",
    "## **Important Terminology**\n",
    "- **Run:** Each step within a trace is represented by a run. A run is a span representing a single unit of work or operation within your LLM application. This could be anything from a single call to an LLM or chain, to a prompt formatting call, to a runnable lambda invocation.\n",
    "- **Thread:** A thread is a sequence of traces representing a single conversation. Many LLM applications have a chatbot-like interface in which the user and the LLM application engage in a multi-turn conversation. Each turn in the conversation is represented as its own trace, but these traces are linked together by being part of the same thread.\n",
    "- **Projects:** A project is a collection of traces. You can think of a project as a container for all the traces that are related to a single application or service. You can have multiple projects, and each project can have multiple traces.\n",
    "- **Feedback:** Feedback allows you to score an individual run based on certain criteria. Each feedback entry consists of a feedback tag and feedback score, and is bound to a run by a unique run ID. Feedback can be continuous or discrete (categorical), and you can reuse feedback tags across different runs within an organization.\n",
    "- **Tags:** Tags are collections of strings that can be attached to runs. You can use tags to do the following in the LangSmith UI: Categorize runs for easier search, Filter runs and Group runs together for analysis.\n",
    "\n",
    "## **What does LangSmith records?**\n",
    "1. Inputs and Outputs\n",
    "2. Token Usage\n",
    "3. Cost\n",
    "4. Latency\n",
    "5. Errors\n",
    "6. Intermediate steps\n",
    "7. Tags\n",
    "8. Metadata\n",
    "9. Feedback\n",
    "\n",
    "[Click Here](https://docs.langchain.com/langsmith/observability-concepts) to read the official LangSmith documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb5521-fde6-4b7a-8356-e2467a5721df",
   "metadata": {},
   "source": [
    "## **Setting up the LangSmith**\n",
    "\n",
    "You need the following before starting:\n",
    "1. LLM API Key\n",
    "2. LANGCHAIN_TRACING_V2=true\n",
    "3. LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "4. LANGCHAIN_API_KEY=`\"<api-key>\"`\n",
    "5. LANGCHAIN_PROJECT=`\"<project-name>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dc076f-3dff-488b-9994-f1737a5c25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup LANGSMITH API Key\n",
    "f = open('keys/.langsmith_api_key.txt')\n",
    "LANGSMITH_API_KEY = f.read()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"my-simple-chain-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd66193-7ca0-4fa0-b898-9047148d2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_langchain/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "    (\"system\", \"You are a polite assistant.\"), \n",
    "    (\"human\", \"{human_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a120e-0141-4539-a109-46dced5b636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "openai_chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, \n",
    "                               model=\"gpt-4o-mini\", \n",
    "                               temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2142de6-dfc7-4344-8144-8411410340b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e09021-6c65-41d8-931e-7e82aa7b9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | openai_chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edef3010-be5c-4cad-9a91-0bfff4bdba24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"human_input\" : \"Hello!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec5a5ac-2240-4936-9653-ceacb134fb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain facilitates language model integration. LangGraph visualizes language model relationships.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuring the Run Name, Tags and Metadata\n",
    "config = {\n",
    "    \"run_name\": \"simple chain\",\n",
    "    \"tags\": [],\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "chain.invoke({\"human_input\" : \"Can you explain in 4-5 words what LangChain and LangGraph does?\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6a8e1-f085-45b5-b093-c397babe5207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
