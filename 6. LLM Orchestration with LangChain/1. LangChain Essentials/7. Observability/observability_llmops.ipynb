{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeb5521-fde6-4b7a-8356-e2467a5721df",
   "metadata": {},
   "source": [
    "# **Adding Observability with LangSmith**\n",
    "\n",
    "## **What's Covered?**\n",
    "1. Introduction to LangSmith\n",
    "    - What is LangSmith?\n",
    "    - What is Observability and Telemetry Data?\n",
    "    - Important Terminology\n",
    "    - What does LangSmith Records?\n",
    "    - Setting up LangSmith\n",
    "2. Example Implementation\n",
    "    - Step 1: Add the required LangSmith environment variables\n",
    "    - Step 2: Create a Chain\n",
    "    - Step 3: Invoking the Chain\n",
    "    - Step 4: Adding the tags and metadata\n",
    "3. Example Implementation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10030f5-4435-42cb-9233-09ff7517c318",
   "metadata": {},
   "source": [
    "## **Introduction to LangSmith**\n",
    "\n",
    "### **What is LangSmith?**\n",
    "Provides observability & evaluation which helps to debug, test and monitor AI systems/workflows. Eg: Identify why your production workflow is taking more time (i.e. latency), measure the cost, token usage, hallucination, etc...\n",
    "\n",
    "### **What is Observability?**\n",
    "Ability to understand a system's internal state by analyzing its external outputs, primarily through telemetry data (i.e. logs, metrics and traces)\n",
    "- **Logs:** Chronological records of events, actions and messages from the system\n",
    "- **Metrics:** Numerical measurement over time eg: CPU usage, number of requests, latency, etc...\n",
    "- **Traces:** Records the journey of a single request as it moves across different services in a distributed system, showing timing and flow.\n",
    "\n",
    "### **Important Terminology**\n",
    "- **Run:** Each step within a trace is represented by a run. A run is a span representing a single unit of work or operation within your LLM application. This could be anything from a single call to an LLM or chain, to a prompt formatting call, to a runnable lambda invocation.\n",
    "- **Thread:** A thread is a sequence of traces representing a single conversation. Many LLM applications have a chatbot-like interface in which the user and the LLM application engage in a multi-turn conversation. Each turn in the conversation is represented as its own trace, but these traces are linked together by being part of the same thread.\n",
    "- **Projects:** A project is a collection of traces. You can think of a project as a container for all the traces that are related to a single application or service. You can have multiple projects, and each project can have multiple traces.\n",
    "- **Feedback:** Feedback allows you to score an individual run based on certain criteria. Each feedback entry consists of a feedback tag and feedback score, and is bound to a run by a unique run ID. Feedback can be continuous or discrete (categorical), and you can reuse feedback tags across different runs within an organization.\n",
    "- **Tags:** Tags are collections of strings that can be attached to runs. You can use tags to do the following in the LangSmith UI: Categorize runs for easier search, Filter runs and Group runs together for analysis.\n",
    "\n",
    "### **What does LangSmith records?**\n",
    "1. Inputs and Outputs\n",
    "2. Token Usage\n",
    "3. Cost\n",
    "4. Latency\n",
    "5. Errors\n",
    "6. Intermediate steps\n",
    "7. Tags\n",
    "8. Metadata\n",
    "9. Feedback\n",
    "\n",
    "[Click Here](https://docs.langchain.com/langsmith/observability-concepts) to read the official LangSmith documentation.\n",
    "\n",
    "### **Setting up LangSmith**\n",
    "\n",
    "You need to setup the following environment variables initially:\n",
    "1. LANGSMITH_TRACING=true\n",
    "2. LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "3. LANGSMITH_API_KEY=`\"<api-key>\"`\n",
    "4. LANGSMITH_PROJECT=`\"<project-name>\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ce482-7afc-41a6-a732-eecb6ea37fe8",
   "metadata": {},
   "source": [
    "## **Example Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883db59-3244-4b14-b138-6298de58b469",
   "metadata": {},
   "source": [
    "### **Step 1: Add the required LangSmith environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dc076f-3dff-488b-9994-f1737a5c25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup LANGSMITH API Key\n",
    "f = open('keys/.langsmith_api_key.txt')\n",
    "LANGSMITH_API_KEY = f.read()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"my-simple-chain-project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a544c5c-e7e1-4ae0-aade-a827186bb882",
   "metadata": {},
   "source": [
    "### **Step 2: Create a Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd66193-7ca0-4fa0-b898-9047148d2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_langchain/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=\n",
    "    [\n",
    "        (\"system\", \"You are a polite assistant.\"), \n",
    "        (\"human\", \"{human_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a120e-0141-4539-a109-46dced5b636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "openai_chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, \n",
    "                               model=\"gpt-4o-mini\", \n",
    "                               temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2142de6-dfc7-4344-8144-8411410340b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e09021-6c65-41d8-931e-7e82aa7b9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | openai_chat_model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e0a88-1755-4a33-8f05-67e2b220bd25",
   "metadata": {},
   "source": [
    "### **Step 3: Invoking the Chain**\n",
    "\n",
    "**Note: By default, LangSmith is going to track all the runs which are called using .invoke() method.**\n",
    "\n",
    "<img src=\"images/project_dashboard.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edef3010-be5c-4cad-9a91-0bfff4bdba24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"human_input\" : \"Hello!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238b188-82c6-4090-8489-b4c04fb807e3",
   "metadata": {},
   "source": [
    "### **Step 4: Adding the tags and metadata**\n",
    "\n",
    "<img src=\"images/run_openai.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec5a5ac-2240-4936-9653-ceacb134fb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain facilitates LLM application development. LangGraph enables graph-based data processing.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuring the Run Name, Tags and Metadata\n",
    "openai_config = {\n",
    "    \"run_name\": \"openai chain\",\n",
    "    \"tags\": [\"openai\", \"gpt-4o-mini\"],\n",
    "    \"metadata\": {\"inference\": \"openai\", \"llm\": \"gpt-4o-mini\"}\n",
    "}\n",
    "\n",
    "chain.invoke({\"human_input\" : \"Can you explain in 4-5 words what LangChain and LangGraph does?\"}, config=openai_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb09b70-68fd-4f94-9d9d-cdb86a8e91df",
   "metadata": {},
   "source": [
    "## **Example Implementation 2**\n",
    "\n",
    "<img src=\"images/run_groq.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15d7588-a9c8-4c19-9216-b913450f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "f = open('keys/.groq_api_key.txt')\n",
    "GROQ_API_KEY = f.read()\n",
    "\n",
    "# Pass the standard parameters during initialization\n",
    "groq_chat_model = ChatGroq(api_key=GROQ_API_KEY, \n",
    "                           model=\"openai/gpt-oss-20b\", \n",
    "                           temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc6a8e1-f085-45b5-b093-c397babe5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_2 = chat_template | groq_chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88987aac-63d9-4f75-abac-68a98f7cbfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- **LangChain:** “Enables building AI apps.”  \\n- **LangGraph:** “Builds knowledge‑graph workflows.”'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuring the Run Name, Tags and Metadata\n",
    "openai_config = {\n",
    "    \"run_name\": \"groq chain\",\n",
    "    \"tags\": [\"groq\", \"gpt-oss-20b\"],\n",
    "    \"metadata\": {\"inference\": \"groq\", \"llm\": \"gpt-oss-20b\"}\n",
    "}\n",
    "\n",
    "chain_2.invoke({\"human_input\" : \"Can you explain in 4-5 words what LangChain and LangGraph does?\"}, config=openai_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
