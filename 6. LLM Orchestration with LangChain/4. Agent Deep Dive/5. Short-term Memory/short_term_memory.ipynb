{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c2f847-bdd2-4fec-ae00-711e822cf52a",
   "metadata": {},
   "source": [
    "### **Runtime Context**\n",
    "\n",
    "LangChain's **create_agent()** runs on LangGraph's runtime under the hood.\n",
    "- LangChain’s agent manages short-term memory by default as a part of your agent’s state.\n",
    "- By storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.\n",
    "- Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n",
    "\n",
    "LangGraph exposes a Runtime object with the following information:\n",
    "1. **Context:** Static information like user id, db connections,, or other dependencies for an agent invocation\n",
    "2. **Store:** A `BaseStore` instance used for **long-term memory**.\n",
    "3. **Stream Writer:** An object used for streaming information via the `\"custom\"` stream mode.\n",
    "\n",
    "You can access runtime information in tools, as well as via custom agent middleware.\n",
    "\n",
    "In this tutorial, we will be covering short-term memory via a checkpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930fbd4-2885-4dac-95aa-38c791faad69",
   "metadata": {},
   "source": [
    "## **Accessing Runtime Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a1c869-a805-49d5-a483-2d6f038df76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "openai_chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, \n",
    "                               model=\"gpt-4o-mini\", \n",
    "                               temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc694fb-6142-48b3-b7b1-53a9f327b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! My name is Bob. Can you provide my information?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_info (call_xUUml1cd3mOR1iZeMCPbzBUv)\n",
      " Call ID: call_xUUml1cd3mOR1iZeMCPbzBUv\n",
      "  Args:\n",
      "    user_name: Bob\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_info\n",
      "\n",
      "Hi Bob, Here is your information.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! Here is your information. If you need anything specific, just let me know!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "def get_user_info(user_name: str):\n",
    "    \"\"\"This function helps retrieve the user's information and details.\"\"\"\n",
    "    return f\"Hi {user_name}, Here is your information.\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    openai_chat_model,\n",
    "    tools=[get_user_info],\n",
    "    checkpointer=InMemorySaver(),  \n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob. Can you provide my information?\"}]},\n",
    "            {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")\n",
    "\n",
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e02b32-afd9-4838-a405-d905bef34fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "279a8d12-859a-4351-badb-27b5aa2db1b1",
   "metadata": {},
   "source": [
    "#### **NOTE**\n",
    "In production, use a checkpointer backed by a database:\n",
    "\n",
    "\n",
    "```python\n",
    "pip install langgraph-checkpoint-postgres\n",
    "```\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver  \n",
    "\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup() # auto create tables in PostgresSql\n",
    "    agent = create_agent(\n",
    "        \"gpt-5\",\n",
    "        tools=[get_user_info],\n",
    "        checkpointer=checkpointer,  \n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e384a-8052-4b8b-84e1-01a39fff3407",
   "metadata": {},
   "source": [
    "## **Customizing Agent Memory**\n",
    "\n",
    "By default, agents use **AgentState** to manage short term memory, specifically the conversation history via a messages key. \n",
    "\n",
    "**Steps to customize**\n",
    "1. Extend AgentState to add additional fields.\n",
    "2. Custom state schemas are passed to create_agent using the **state_schema** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99798b14-3fc1-4aae-9e0d-f6c56d942d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "\n",
    "class CustomAgentState(AgentState):  \n",
    "    user_id: str\n",
    "    preferences: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543a7f-77d5-4438-b2fc-90e27d21849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5\",\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomAgentState,  \n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",  \n",
    "        \"preferences\": {\"theme\": \"dark\"}  \n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6cd92-d804-4464-8356-3e599a5f7bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6107bf-5ad6-496c-b423-8caa4df32a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f29da-734a-4acf-8891-d296fd095ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cfd2b-6ba3-4337-adf1-e71bb19b7548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f129cf-bec2-47c8-af7c-b678774bf61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb7a1d6-9e42-4f3d-8063-3adc30f455c6",
   "metadata": {},
   "source": [
    "Reference: https://docs.langchain.com/oss/python/langchain/short-term-memory\n",
    "\n",
    "### **Define Agent State with middleware**\n",
    "\n",
    "Use middleware to define custom state when your custom state needs to be accessed by specific middleware hooks and tools attached to said middleware.\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/agents#memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61187e89-42ac-46e7-9292-3825daaef988",
   "metadata": {},
   "source": [
    "## **Agent Memory**\n",
    "\n",
    "Agents maintain conversation history automatically through the message state. You can also configure the agent to use a custom state schema to remember additional information during the conversation.\n",
    "\n",
    "Information stored in the state can be thought of as the **short-term memory** of the agent:\n",
    "\n",
    "Custom state schemas must extend AgentState as a TypedDict.\n",
    "\n",
    "There are two ways to define custom state:\n",
    "- Via middleware (preferred)\n",
    "- Via state_schema on create_agent\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Custom State Schema (Beyond Messages)\n",
    "\n",
    "**Add fields like `user_preferences` to state for memory/tools.**\n",
    "\n",
    "```python\n",
    "import pydantic\n",
    "state_schema = pydantic.BaseModel(\n",
    "    messages=list[str],\n",
    "    user_preferences=dict[str, str]  # Persists across calls\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    state_schema=state_schema\n",
    ")\n",
    "```\n",
    "\n",
    "## Step 7: Production Features (LangGraph Under the Hood)\n",
    "\n",
    "**Persistence, HiT-L, time-travel out-of-box:**\n",
    "\n",
    "```python\n",
    "from langgraph.store.memory import InMemoryStore  # Or PostgresStore\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    store=InMemoryStore(),  # Checkpoints across sessions\n",
    "    # Interrupts via middleware (Step 4)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10640c-2b14-4e81-b621-46589a590669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
