{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4a0032-6f3e-40ce-abc3-e3e48ad11dd0",
   "metadata": {},
   "source": [
    "# **Middlewares**\n",
    "\n",
    "Middleware provides a way to more tightly control what happens inside the agent. Middleware is useful for the following:\n",
    "- Tracking agent behavior with logging, analytics, and debugging.\n",
    "- Transforming prompts, tool selection, and output formatting.\n",
    "- Adding retries, fallbacks, and early termination logic.\n",
    "- Applying rate limits, guardrails, and PII detection.\n",
    "\n",
    "Add middleware by passing them to `create_agent`:\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware, HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(...),\n",
    "        HumanInTheLoopMiddleware(...)\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "### **Built-in Middleware (Provider Agnostic)**\n",
    "\n",
    "LangChain provides prebuilt middleware for common use cases. Each middleware is production-ready and configurable for your specific needs. The following middleware work with any LLM provider:\n",
    "| Middleware            | Description                                                                 |\n",
    "|-----------------------|-----------------------------------------------------------------------------|\n",
    "| Summarization         | Automatically summarize conversation history when approaching token limits. |\n",
    "| Human-in-the-loop     | Pause execution for human approval of tool calls.                            |\n",
    "| Model call limit      | Limit the number of model calls to prevent excessive costs.                  |\n",
    "| Tool call limit       | Control tool execution by limiting call counts.                              |\n",
    "| Model fallback        | Automatically fallback to alternative models when the primary fails.        |\n",
    "| PII detection         | Detect and handle Personally Identifiable Information (PII).                |\n",
    "| To-do list            | Equip agents with task planning and tracking capabilities.                  |\n",
    "| LLM tool selector     | Use an LLM to select relevant tools before calling the main model.           |\n",
    "| Tool retry            | Automatically retry failed tool calls with exponential backoff.             |\n",
    "| Model retry           | Automatically retry failed model calls with exponential backoff.            |\n",
    "| LLM tool emulator     | Emulate tool execution using an LLM for testing purposes.                   |\n",
    "| Context editing       | Manage conversation context by trimming or clearing tool uses.              |\n",
    "| Shell tool            | Expose a persistent shell session to agents for command execution.           |\n",
    "| File search           | Provide Glob and Grep search tools over filesystem files.                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca53ec6-4fec-4bcf-9037-c9a274224a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d69638-3c9b-4dad-b10e-b40400c8a066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31687e4-96bd-4896-968c-0167caa9b121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbe5a3-28af-4c94-84fa-a0d968b0cc13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ceb82-4326-4909-9084-62949340a3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3c169-8b44-4d1f-b562-4bbcf25fce13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b097263-9019-443c-916d-b32fe1422c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cab8d-ebe6-4a5a-88ac-44cde0ad5347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffca9805-30c3-4510-bbf1-22d56a5a4d4b",
   "metadata": {},
   "source": [
    "### **Middleware**\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/middleware/overview\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/middleware/built-in\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/middleware/custom\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/runtime\n",
    "\n",
    "Test:\n",
    "https://docs.langchain.com/oss/python/langchain/test\n",
    "\n",
    "API Reference:  \n",
    "https://reference.langchain.com/python/langchain/middleware/?_gl=1*1akd7zx*_gcl_au*ODYzMzY4ODc1LjE3NjM4MjAwNjA.*_ga*MTk3NjE3OTA4MC4xNzIzMDI3MjE3*_ga_47WX3HKKY2*czE3NjU5MDcxNjIkbzY2JGcxJHQxNzY1OTA3MzExJGo2MCRsMCRoMA.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77be07-6437-4fc8-b6b2-99254289a253",
   "metadata": {},
   "source": [
    "### **Define Agent State with middleware**\n",
    "\n",
    "Use middleware to define custom state when your custom state needs to be accessed by specific middleware hooks and tools attached to said middleware.\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/agents#memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37770fe9-5155-490f-aebc-82c51c04aae2",
   "metadata": {},
   "source": [
    "### **Context Engineering (Model, Tool and Lifecycle)**\n",
    "\n",
    "LangChain middleware is the mechanism under the hood that makes context engineering practical for developers using LangChain.\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/context-engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a78825-e56c-4341-971f-ffb14a997f55",
   "metadata": {},
   "source": [
    "## **Dynamic Model Selection and Prompt Selection**\n",
    "\n",
    "@wrap_model_call:\n",
    "- https://docs.langchain.com/oss/python/langchain/agents#dynamic-model\n",
    "\n",
    "@dynamic_prompt:\n",
    "- https://docs.langchain.com/oss/python/langchain/agents#dynamic-system-prompt\n",
    "\n",
    "## **Tool Error Handling**\n",
    "\n",
    "@wrap_tool_call:\n",
    "- https://docs.langchain.com/oss/python/langchain/agents#tool-error-handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829ca14-3d61-439c-ab97-c779deeb5f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf15136-f7af-4610-93e9-98cec96a7e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7023bdd-306b-4f42-944b-53f2a6fd5db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c06e8b-fa0b-423b-bc9e-b38aebecbbdc",
   "metadata": {},
   "source": [
    "## **Agent Memory**\n",
    "\n",
    "Agents maintain conversation history automatically through the message state. You can also configure the agent to use a custom state schema to remember additional information during the conversation.\n",
    "\n",
    "Information stored in the state can be thought of as the **short-term memory** of the agent:\n",
    "\n",
    "Custom state schemas must extend AgentState as a TypedDict.\n",
    "\n",
    "There are two ways to define custom state:\n",
    "- Via middleware (preferred)\n",
    "- Via state_schema on create_agent\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Custom State Schema (Beyond Messages)\n",
    "\n",
    "**Add fields like `user_preferences` to state for memory/tools.**\n",
    "\n",
    "```python\n",
    "import pydantic\n",
    "state_schema = pydantic.BaseModel(\n",
    "    messages=list[str],\n",
    "    user_preferences=dict[str, str]  # Persists across calls\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    state_schema=state_schema\n",
    ")\n",
    "```\n",
    "\n",
    "## Step 4: Built-in Middleware (Prebuilt Superpowers)\n",
    "\n",
    "**Add via `middleware=[]` list. Stack them.**\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import (\n",
    "    summarization_middleware,\n",
    "    human_in_the_loop_middleware,\n",
    "    pii_redaction_middleware\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        summarization_middleware(model=\"gpt-4o-mini\", trigger={\"tokens\": 500}),  # Auto-summarize history\n",
    "        human_in_the_loop_middleware(interrupt_on={\"get_weather\": {\"allowed_decisions\": [\"approve\", \"reject\"]}}),  # HiT-L\n",
    "        pii_redaction_middleware(patterns=[\"email\", \"phone\"])  # Scrub PII\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "## Step 5: Custom Middleware (Advanced Hooks)\n",
    "\n",
    "**Subclass `AgentMiddleware` for `wrap_model_call`, `wrap_tool_call`, etc.**\n",
    "\n",
    "```python\n",
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "    def wrap_model_call(self, request, handler):\n",
    "        if len(request.state[\"messages\"]) > 10:  # Complex conv â†’ better model\n",
    "            request.model = ChatOpenAI(model=\"gpt-4o\")\n",
    "        return handler(request)\n",
    "\n",
    "agent = create_agent(model=model, middleware=[DynamicModelMiddleware()])\n",
    "```\n",
    "\n",
    "Hooks: `before_model`, `wrap_tool_call`, `after_model`, etc.\n",
    "\n",
    "## Step 7: Production Features (LangGraph Under the Hood)\n",
    "\n",
    "**Persistence, HiT-L, time-travel out-of-box:**\n",
    "\n",
    "```python\n",
    "from langgraph.store.memory import InMemoryStore  # Or PostgresStore\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    store=InMemoryStore(),  # Checkpoints across sessions\n",
    "    # Interrupts via middleware (Step 4)\n",
    ")\n",
    "```\n",
    "\n",
    "**Debug:** Traces auto-sent to LangSmith.\n",
    "\n",
    "## [Next: LangGraph for Multi-Agent/Complex Flows]\n",
    "\n",
    "When `create_agent` limits hit (custom edges, subgraphs), migrate to raw LangGraph graphs.\n",
    "\n",
    "**Relevant docs:**\n",
    "- [Agents](https://docs.langchain.com/oss/python/langchain/agents)\n",
    "- [Tools](https://docs.langchain.com/oss/python/langchain/tools)\n",
    "- [Middleware](https://docs.langchain.com/oss/python/langchain/middleware/built-in)\n",
    "- [Streaming](https://docs.langchain.com/oss/python/langchain/streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d2a7d-4fcb-470a-8ce2-24b62cb6d589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
