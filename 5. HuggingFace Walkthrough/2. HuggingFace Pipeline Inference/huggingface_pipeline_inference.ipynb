{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f5314b-f295-4177-afe0-20d8ac40d9bb",
   "metadata": {},
   "source": [
    "# **ðŸ¤— Pipeline Inference**\n",
    "\n",
    "1. Pipelines\n",
    "    - What is pipeline()?\n",
    "    - Pipeline syntax\n",
    "    - Behind the Scenes\n",
    "    - Key Points\n",
    "2. Default Model List\n",
    "    - Natural Language Processing\n",
    "    - Computer Vision\n",
    "    - Identify the Pipeline Supported Tasks\n",
    "3. Practical Natural Language Processing Use Cases\n",
    "    - Loading the text data\n",
    "    - NLP Task 1 - Text Classification\n",
    "    - NLP Task 2 - Named Entity Recognition\n",
    "    - NLP Task 3 - Summarization\n",
    "    - NLP Task 4 - Question Answering\n",
    "    - NLP Task 5 - Translation\n",
    "    - NLP Task 6 - Text Generation\n",
    "    - NLP Task 7 - Fill-Mask\n",
    "    - NLP Task 8 - Feature Extraction\n",
    "4. Practical Computer Vision Use Cases\n",
    "    - Loading the image data\n",
    "    - CV Task 1 - Image Classification\n",
    "    - CV Task 2 - Object Detection\n",
    "    - CV Task 3 - Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d26bf-3574-4f2d-a7c5-e30ab428d217",
   "metadata": {},
   "source": [
    "## **Pipelines**\n",
    "\n",
    "### **What is pipeline()?**\n",
    "The `pipeline()` makes it simple to use any model from the `Hub` for inference on any language, computer vision, speech, and multimodal tasks. Even if you donâ€™t have experience with a specific modality or arenâ€™t familiar with the underlying code behind the models, you can still use them for inference with the `pipeline()`! \n",
    "\n",
    "It is the most powerful way to start using pre-trained Hugging Face models. \n",
    "\n",
    "It's a high level API that abstracts away all the complexity of tokenization, model loading, and post-processing, allowing you to perform common tasks with just a few lines of code.\n",
    "\n",
    "### **Common Tasks Supported**\n",
    "- sentiment-analysis\n",
    "- text-generation\n",
    "- ner\n",
    "- summarization\n",
    "- translation\n",
    "- question-answering\n",
    "- fill-mask (predicting missing words)\n",
    "- zero-shot-classification (classifying text without specific training examples)\n",
    "- ... and many more!\n",
    "\n",
    "Explore more on:  \n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "### **Pipeline syntax**\n",
    "1. Start by importing `pipeline`\n",
    "```python\n",
    "from transformers import pipeline\n",
    "```\n",
    "2. Specify the inference task\n",
    "```python\n",
    "classifier = pipeline(task=\"text-classification\")\n",
    "```\n",
    "3. Pass the input to the `pipeline()`\n",
    "```python\n",
    "classifier(input_text)\n",
    "```\n",
    "\n",
    "### **Behind the Scenes**\n",
    "- Determine framework (py/tf/jax)\n",
    "- Loads tokenizer\n",
    "- Loads model\n",
    "- Choose Device (MPS/CUDA/CPU)\n",
    "- Handles pre/post-processing\n",
    "- Gives results\n",
    "\n",
    "### **Key Points**\n",
    "- The first time you run a pipeline for a specific model, it will download the model weights (which can be several hundred MB to GBs).\n",
    "- Subsequent runs will use the cached version.\n",
    "- You can specify a particular model within the pipeline if you don't want the default.\n",
    "- The output format of the pipeline varies depending on the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada8379-8486-4df3-a5ec-b19d9d070689",
   "metadata": {},
   "source": [
    "### **Example Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2e61a-613e-4a22-8fed-5b23ac6a79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "classifier = pipeline(task=\"text-classification\")\n",
    "\n",
    "classifier(\"It was a very bad movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe869da2-c0de-4819-b982-b185bb3c7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1f23-eb6b-41ee-b830-4523dea2e30e",
   "metadata": {},
   "source": [
    "**Important**\n",
    "Transformers needs to decide:\n",
    "- Should I load a PyTorch model? (pt)\n",
    "- Should I load a TensorFlow model? (tf)\n",
    "- Which AutoModel class is correct?\n",
    "- If the user didnâ€™t specify a model, which model should I default to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8712c-767f-4e8b-a3c0-023483fd9772",
   "metadata": {},
   "source": [
    "## **Default Model List**\n",
    "\n",
    "### **Natural Language Processing**\n",
    "For Natural Language Processing, the following are the default models for respective tasks.\n",
    "\n",
    "- Text classification:Â `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "- Token classification:Â `dslim/bert-base-NER`\n",
    "- Text summarization:Â `sshleifer/distilbart-cnn-12-6`\n",
    "- Question answering:Â `distilbert-base-cased-distilled-squad`\n",
    "- Text generation:Â `gpt2`\n",
    "- Text similarity:Â `sentence-transformers/all-mpnet-base-v2`\n",
    "- Translation:Â `t5-base`\n",
    "- Fill mask:Â `distilroberta-base`\n",
    "\n",
    "### **Computer Vision**\n",
    "The default models for computer vision tasks are as follows:\n",
    "\n",
    "- Image classification:Â `google/vit-base-patch16-224`\n",
    "- Object detection:Â `facebook/detr-resnet-50`\n",
    "- Segmentation:Â `facebook/detr-resnet-50-panoptic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e5a41-50be-4381-af41-51ffe9649ead",
   "metadata": {},
   "source": [
    "### **Identify the Pipeline Supported Tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418eec2-87ed-4a38-89e6-16fccc1da480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS\n",
    "print(SUPPORTED_TASKS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047e106-b6ee-465d-9bbd-2c325eebc0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_TASKS[\"audio-classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec7624-89dd-49f6-ae3f-49d15d265c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_TASKS[\"text-classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c151a-d27d-4770-b891-8ae611be7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your dictionary (assign it to a variable)\n",
    "data = SUPPORTED_TASKS   # Replace this with your dict variable name\n",
    "\n",
    "rows = []\n",
    "\n",
    "for task, info in data.items():\n",
    "    impl = info.get(\"impl\", None)\n",
    "\n",
    "    # Extract PyTorch model classes\n",
    "    pt_models = [m.__name__ for m in info.get(\"pt\", [])]\n",
    "\n",
    "    # Extract TensorFlow model classes\n",
    "    tf_models = [m.__name__ for m in info.get(\"tf\", [])]\n",
    "\n",
    "    # Extract default model names\n",
    "    default_entry = info.get(\"default\", {})\n",
    "    default_model_dict = default_entry.get(\"model\", {})\n",
    "\n",
    "    default_pt = None\n",
    "    default_tf = None\n",
    "\n",
    "    if \"pt\" in default_model_dict:\n",
    "        default_pt = default_model_dict[\"pt\"][0]   # (model_name, revision)\n",
    "    if \"tf\" in default_model_dict:\n",
    "        default_tf = default_model_dict[\"tf\"][0]\n",
    "\n",
    "    rows.append({\n",
    "        \"task\": task,\n",
    "        \"type\": info.get(\"type\"),\n",
    "        \"impl\": impl.__name__ if impl else None,\n",
    "        \"pt_models\": pt_models,\n",
    "        \"tf_models\": tf_models,\n",
    "        \"default_pt_model\": default_pt,\n",
    "        \"default_tf_model\": default_tf,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dae34-b03c-41fe-8521-446145553a79",
   "metadata": {},
   "source": [
    "## **Practical Natural Language Processing Use Cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776edb4b-e284-4552-91fa-1ddbd80f22bf",
   "metadata": {},
   "source": [
    "### **Loading the text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0dcc6-3409-496a-9cbf-e82e5e3a22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text/email.txt\") as f:\n",
    "    email = f.read()\n",
    "\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a38fc1-073e-4b10-a3d2-b0f2bc481220",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text/product_review.txt\") as f:\n",
    "    product_review = f.read()\n",
    "\n",
    "print(product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537f411-3449-40f1-b9cb-774b2276875f",
   "metadata": {},
   "source": [
    "### **NLP Task 1 - Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5599020-3566-4869-b441-809040222dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "classifier = pipeline(task=\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219e2e4-7006-4904-b8a0-eb1dc5c7faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "classifier(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3134085-87b5-45df-9d12-a593c33e5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "classifier(product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af70dfb-b447-4fd6-98a3-ba4683fa8991",
   "metadata": {},
   "source": [
    "### **NLP Task 2 - Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d82142-5efb-47dd-80b5-98727336e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "ner_tagger = pipeline(task=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c20ba3-4b9d-42ae-8436-32d37f72315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "ner_tagger(email)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e00ee-d406-472f-bab7-3fb248a8cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "ner_tagger(product_review)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b006-13aa-4516-b934-7ba58d764306",
   "metadata": {},
   "source": [
    "### **NLP Task 3 - Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ff6f1-7b0d-4196-ab7b-009c459f22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "summarizer = pipeline(task=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d76033-dcb2-4b60-8d75-839cb6f5056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "summarizer(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643167fe-f455-4325-9d32-373d935fb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "summarizer(product_review, max_length=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750211f-c82f-421c-ab4d-7c118f4ffea6",
   "metadata": {},
   "source": [
    "### **NLP Task 4 - Question Answering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66df60c-1ff0-49fe-ac90-4e2933b14780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "reader = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e13acf-412f-4514-8208-f7a87d7117c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"When is the Offer Letter going to be shared?\"\n",
    "\n",
    "reader(question=question, context=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57423c-f7da-4788-b0ae-59a21086a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"When is internship starting?\"\n",
    "\n",
    "reader(question=question, context=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b976ff-e3f3-4d31-9fe0-70ba9d50c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"Where did the customer buy the product?\"\n",
    "\n",
    "reader(question=question, context=product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28a652-4bf7-4637-957b-c62919d204b8",
   "metadata": {},
   "source": [
    "### **NLP Task 5 - Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfb923-9037-48aa-9e25-742462e96f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704b813-4358-4972-8254-b03ba463f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "translator(email, max_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59fa1f3-62cf-4983-b5af-22d83e5d5f0f",
   "metadata": {},
   "source": [
    "### **NLP Task 6 - Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea4f42-f770-4476-8fac-17d050ea84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26ee0a-f885-4282-8c96-7ff9ce979508",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a helpful AI assistant. Can you help me write the response for the following product review:\n",
    "### PRODUCT REVIEW ###\n",
    "{product_review}\n",
    "\n",
    "### CUSTOMER SERVICE RESPONSE ###\n",
    "Dear Customer, I am sorry to hear this. Please be assured that \n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3b262-35aa-4531-8de5-13888cdba6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "response = generator(prompt, max_length=200)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fd239-0ca5-4752-aa9f-72232711cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46a674-1f71-4194-b2d1-bb2718d0e389",
   "metadata": {},
   "source": [
    "### **NLP Task 7 - Fill-Mask**\n",
    "\n",
    "Use Cases: Correcting the misprinted words in a book, guessing the lost words from the ancient manuscripts, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508958e-95e5-4a8c-87f7-4cf9bb7a89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "unmasker = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51110399-3e8b-4419-a76c-bf5727f0959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "unmasker(\"Artificial Intelligence <mask> take over the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c902c2-7ded-46ea-9731-e9e6d4a1440e",
   "metadata": {},
   "source": [
    "### **NLP Task 8 - Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2dadbd-2128-4cd4-945f-199227f0641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the feature extraction pipeline and model\n",
    "pipe = pipeline('feature-extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c459ae8-e467-4569-82d1-1bfe9a187dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "AI encompasses a range of technologies, including machine learning, \n",
    "natural language processing, robotics, and more.\n",
    "\"\"\"\n",
    "\n",
    "# Get embeddings\n",
    "embedding = pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5409db2-6486-40cf-a4a7-623a939c143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is a list with one item per sentence\n",
    "sentence_embeddings = embedding[0][0][0:10]\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05426a5c-b488-44b2-a1b1-df3fb3e1e1c2",
   "metadata": {},
   "source": [
    "## **Practical Computer Vision Use Cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a909b-0a32-4a6f-905b-a1ec544d2f35",
   "metadata": {},
   "source": [
    "### **Loading the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8315d74-501c-444a-a075-1fd07610b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509caef4-a7ca-4992-b8a7-db9e556d4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cats_img = Image.open(\"images/image_1.jpg\")\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(cats_img)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87bb47-fb74-45b6-aaca-25d385492a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_img = Image.open(\"images/image_2.jpeg\")\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(traffic_img)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382499fb-552b-4dc5-9188-382ea0a1efb9",
   "metadata": {},
   "source": [
    "### **CV Task 1 - Image Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201f5d8-0900-4f81-9ddd-05acffa739b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "image_classifier = pipeline(\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e2aed-a25e-4554-b83a-26cf176f3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "image_classifier(cats_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cf71a-c90d-4079-bc86-a45f84c754cf",
   "metadata": {},
   "source": [
    "### **CV Task 2 - Object Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b98c5-25e6-4865-a941-7826055d5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90484266-d72e-46cf-bc9c-5b40682f57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "object_detection = pipeline(\"object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67f4f9-3d27-432e-b6d9-9997533322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "detections = object_detection(traffic_img)\n",
    "\n",
    "detections[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324f59f-2f2c-4b70-b35d-f79089926fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a drawing context\n",
    "draw = ImageDraw.Draw(traffic_img)\n",
    "\n",
    "# Define a font (optional)\n",
    "font = ImageFont.load_default(45)\n",
    "\n",
    "# Draw the bounding boxes and labels\n",
    "for detection in detections:\n",
    "    box = detection['box']\n",
    "    label = detection['label']\n",
    "    score = detection['score']\n",
    "    \n",
    "    # Define the rectangle coordinates\n",
    "    xmin, ymin, xmax, ymax = box['xmin'], box['ymin'], box['xmax'], box['ymax']\n",
    "    \n",
    "    # Draw the rectangle\n",
    "    draw.rectangle([(xmin, ymin), (xmax, ymax)], outline=\"red\", width=4)\n",
    "    \n",
    "    # Prepare the label text\n",
    "    text = f\"{label}: {score:.2f}\"\n",
    "    \n",
    "    # Get text size\n",
    "    text_bbox = draw.textbbox((xmin, ymin), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "    \n",
    "    # Draw the text background rectangle\n",
    "    draw.rectangle([(xmin, ymin - text_height), (xmin + text_width, ymin)], fill=\"red\")\n",
    "    \n",
    "    # Draw the text\n",
    "    draw.text((xmin, ymin - text_height), text, fill=\"white\", font=font)\n",
    "\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(traffic_img)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927990e-5620-4264-8123-6de2df9cf8a3",
   "metadata": {},
   "source": [
    "### **CV Task 3 - Image Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd04154-c56f-49a5-bb17-2ffe6dbd23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "image_segmentation = pipeline(\"image-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513db87-d472-49fb-93a8-4d53ca67e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "segments = image_segmentation(cats_img)\n",
    "\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f3c8b-2d61-4d2b-aee0-21ccbac363d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(segments[4][\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdaba1-06ea-4974-869b-821589dcbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15f012-ba2f-44e0-b974-53740a6b9b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
