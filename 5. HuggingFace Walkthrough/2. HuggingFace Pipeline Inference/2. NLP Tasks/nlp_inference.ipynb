{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4dae34-b03c-41fe-8521-446145553a79",
   "metadata": {},
   "source": [
    "# **Practical Natural Language Processing Use Cases**\n",
    "\n",
    "## **What's Covered?**\n",
    "\n",
    "1. Loading the text data\n",
    "2. Classification\n",
    "    - What is Classification?\n",
    "    - Types of Classification\n",
    "    - Example Usage - Text Classification\n",
    "    - Example Usage - Token Classification\n",
    "3. Summarization\n",
    "    - What is Summarization?\n",
    "    - Types of Summarization\n",
    "    - Example Usage - Abstractive Summarization\n",
    "4. Translation\n",
    "    - What is Machine Translation?\n",
    "    - Example Usage - Machine Translation\n",
    "    - Understanding Language‚ÄìScript Codes in Multilingual AI Systems\n",
    "        - Language_Script Code Format\n",
    "        - Why Script Matters?\n",
    "        - How the Model Sees This Difference?\n",
    "        - Common Script Codes\n",
    "        - Codes for Indian Languages\n",
    "        - Codes for Popular International Languages\n",
    "        - Key Takeaway\n",
    "5. Question Answering\n",
    "    - What is QA Task?\n",
    "    - Example Usage - QA Task\n",
    "6. Text Generation\n",
    "    - What is Text Generation?\n",
    "    - Example Usage - Text Generation\n",
    "7. Fill-Mask\n",
    "    - What is Fill-Mask Task?\n",
    "    - Example Usage - Fill Mask\n",
    "8. Feature Extraction\n",
    "    - What is Feature Extraction?\n",
    "    - Example Usage - Feature Extraction\n",
    "9. Sentence Similarity\n",
    "    - What is Sentence Similarity?\n",
    "    - Installing sentence-transformers\n",
    "    - Example Usage - Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776edb4b-e284-4552-91fa-1ddbd80f22bf",
   "metadata": {},
   "source": [
    "### **Loading the text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e0dcc6-3409-496a-9cbf-e82e5e3a22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations Alice ‚Äì Welcome to the GenAI Internship Program!\n",
      "\n",
      "Dear Alice,\n",
      "\n",
      "Congratulations! üéâ\n",
      "\n",
      "We are thrilled to inform you that you have been selected for the GenAI Internship Program, starting on 25th of this month. Your application stood out among thousands, and we‚Äôre excited to have you on board as part of this prestigious program.\n",
      "\n",
      "The official offer letters will be shared with all selected candidates on 20th of this month. Please keep an eye on your inbox and reach out in case you do not receive it by the end of that day.\n",
      "\n",
      "We look forward to your active participation and can‚Äôt wait to see the incredible work you‚Äôll do during this internship!\n",
      "\n",
      "Best regards,\n",
      "Program Coordinator\n",
      "GenAI Internship Team\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"text/email.txt\") as f:\n",
    "    email = f.read()\n",
    "\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a38fc1-073e-4b10-a3d2-b0f2bc481220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought this product from Flipkart website.\n",
      "This product is very worst and replacement policy is very bad. Even I went to their New Delhi support center.\n",
      "I used this laptop only for 30 minute and suddenly it turn off and it will never turn on.\n",
      "And Flipkart website does not replace this product. I should have gone for better brands like Apple or Alienware.\n"
     ]
    }
   ],
   "source": [
    "with open(\"text/product_review.txt\") as f:\n",
    "    product_review = f.read()\n",
    "\n",
    "print(product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489afdd9-90d8-4e5b-8bcd-feff510d99ac",
   "metadata": {},
   "source": [
    "## **Classification**\n",
    "### **What is Classification?**\n",
    "Classification is the task of predicting a discrete label for an input sequence using a learned representation of that sequence.\n",
    "\n",
    "### **Types of Classification**\n",
    "\n",
    "- **Text classification:** You give the whole sentence to the model. The model gives one label for the entire sentence.\n",
    "- **Token classification:** You give the sentence to the model. The model gives a label for every word (token) inside that sentence.\n",
    "\n",
    "| Task                 | What gets classified                  |\n",
    "| -------------------- | ------------------------------------- |\n",
    "| Text classification  | The whole sentence / document         |\n",
    "| Token classification | Each word / token inside the sentence |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537f411-3449-40f1-b9cb-774b2276875f",
   "metadata": {},
   "source": [
    "### **Example Usage - Text Classification**\n",
    "\n",
    "Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5599020-3566-4869-b441-809040222dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the inference task\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c219e2e4-7006-4904-b8a0-eb1dc5c7faa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998281002044678}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "classifier(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3134085-87b5-45df-9d12-a593c33e5b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9983298182487488}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "classifier(product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af70dfb-b447-4fd6-98a3-ba4683fa8991",
   "metadata": {},
   "source": [
    "### **Example Usage - Token Classification**\n",
    "\n",
    "Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks.\n",
    "\n",
    "One interesting usecase is: **Information Extraction from Invoices**.\n",
    "\n",
    "You can extract entities of interest from invoices automatically using Named Entity Recognition (NER) models. Invoices can be read with Optical Character Recognition models and the output can be used to do inference with NER models. In this way, important information such as date, company name, and other named entities can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d82142-5efb-47dd-80b5-98727336e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the inference task\n",
    "ner_tagger = pipeline(\n",
    "    task=\"token-classification\",\n",
    "    model=\"dslim/bert-base-NER\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c20ba3-4b9d-42ae-8436-32d37f72315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.945688,\n",
       "  'index': 3,\n",
       "  'word': 'Alice',\n",
       "  'start': 16,\n",
       "  'end': 21},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.9159807,\n",
       "  'index': 8,\n",
       "  'word': 'Gen',\n",
       "  'start': 39,\n",
       "  'end': 42},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.8153882,\n",
       "  'index': 9,\n",
       "  'word': '##A',\n",
       "  'start': 42,\n",
       "  'end': 43},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.7519947,\n",
       "  'index': 10,\n",
       "  'word': '##I',\n",
       "  'start': 43,\n",
       "  'end': 44}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "ner_tagger(email)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27e00ee-d406-472f-bab7-3fb248a8cf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-ORG',\n",
       "  'score': 0.9920954,\n",
       "  'index': 6,\n",
       "  'word': 'F',\n",
       "  'start': 27,\n",
       "  'end': 28},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.6834046,\n",
       "  'index': 7,\n",
       "  'word': '##lip',\n",
       "  'start': 28,\n",
       "  'end': 31},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.98762983,\n",
       "  'index': 8,\n",
       "  'word': '##kar',\n",
       "  'start': 31,\n",
       "  'end': 34},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.94635123,\n",
       "  'index': 9,\n",
       "  'word': '##t',\n",
       "  'start': 34,\n",
       "  'end': 35}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "ner_tagger(product_review)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b006-13aa-4516-b934-7ba58d764306",
   "metadata": {},
   "source": [
    "## **Summarization**\n",
    "\n",
    "### **What is Summarization?**\n",
    "Summarization is a **sequence-to-sequence generative task** where a model learns to generate a shorter, semantically faithful text conditioned on a longer input document. \n",
    "\n",
    "Summarization requires:\n",
    "- information selection\n",
    "- redundancy removal\n",
    "- content compression\n",
    "- coherence preservation\n",
    "- rephrasing\n",
    "\n",
    "In simple terms, summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text.\n",
    "\n",
    "\n",
    "### **Types of Summarization**\n",
    "- **Extractive summarization:** The summary is built by selecting and reusing parts of the original text. Technically, this can be framed as a sentence-level or token-level selection problem.\n",
    "- **Abstractive summarization:** The summary is newly generated text. It may contain words or phrases not present in the original document. Modern LLM-based summarization is almost always abstractive summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da997a1-c403-40ea-8ce2-aa9a04568d25",
   "metadata": {},
   "source": [
    "### **Example Usage - Abstractive Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1ff6f1-7b0d-4196-ab7b-009c459f22dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the inference task\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d76033-dcb2-4b60-8d75-839cb6f5056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Alice has been selected for the GenAI Internship Program. Her internship will start on 25th of this month. The official offer letters will be shared with all selected candidates on 20th of the month. We can‚Äôt wait to see the incredible work you‚Äôll do during this internship!'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "summarizer(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "643167fe-f455-4325-9d32-373d935fb982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'I used this laptop only for 30 minute and suddenly it turn off and it will never turn on. Flipkart website does not replace this product. I should have gone for better brands like Apple or Alienware. Even I went to their New Delhi support center. I bought this product'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "summarizer(product_review, max_length=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28a652-4bf7-4637-957b-c62919d204b8",
   "metadata": {},
   "source": [
    "## **Translation**\n",
    "\n",
    "### **What is Machine Translation?**\n",
    "Machine translation is a sequence-to-sequence learning task where a neural model encodes a source sentence and autoregressively decodes a target sentence in another language conditioned on the encoded source representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bc276-a31d-4f61-96d6-f610cb3aae41",
   "metadata": {},
   "source": [
    "### **Example Usage - Machine Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0dfb923-9037-48aa-9e25-742462e96f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9131b7770c2b4691886712e0980ef472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e198c2116840329b8a8409eed32d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d860d358ed46a98ec4469bceac453f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e6b93aff8f449abde166e44749b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6260112facf4da1aa2bd60b6a5c4303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the inference task\n",
    "translator = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ") \n",
    "\n",
    "# NLLB: No Language Left Behind: 'nllb-200-distilled-600M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8704b813-4358-4972-8254-b03ba463f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input to the pipeline\n",
    "text_translated = translator(\n",
    "    email, \n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f65accd-629f-4c0e-935b-fbd4b25a5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '‡§¨‡§ß‡§æ‡§à ‡§è‡§≤‡§ø‡§∏  ‡§ú‡•Ä‡§è‡§®‡§è‡§Ü‡§à ‡§á‡§Ç‡§ü‡§∞‡•ç‡§®‡§∂‡§ø‡§™ ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! ‡§™‡•ç‡§∞‡§ø‡§Ø ‡§è‡§≤‡§ø‡§∏, ‡§¨‡§ß‡§æ‡§à!  ‡§π‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§Ø‡§π ‡§¨‡§§‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§á‡§∏ ‡§Æ‡§π‡•Ä‡§®‡•á ‡§ï‡•Ä 25 ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§∏‡•á ‡§∂‡•Å‡§∞‡•Ç ‡§π‡•ã‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ú‡•Ä‡§è‡§®‡§è‡§Ü‡§à ‡§á‡§Ç‡§ü‡§∞‡•ç‡§®‡§∂‡§ø‡§™ ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•Å‡§®‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡•á ‡§Ü‡§µ‡•á‡§¶‡§® ‡§π‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è, ‡§î‡§∞ ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§á‡§∏ ‡§™‡•ç‡§∞‡§§‡§ø‡§∑‡•ç‡§†‡§ø‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§ï‡•á ‡§π‡§ø‡§∏‡•ç‡§∏‡•á ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§∞‡•ç‡§° ‡§™‡§∞ ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§ë‡§´‡§∞ ‡§™‡§§‡•ç‡§∞ ‡§á‡§∏ ‡§Æ‡§π‡•Ä‡§®‡•á ‡§ï‡•Ä 20 ‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§ï‡•ã ‡§∏‡§≠‡•Ä ‡§ö‡§Ø‡§®‡§ø‡§§ ‡§â‡§Æ‡•ç‡§Æ‡•Ä‡§¶‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§è‡§Ç‡§ó‡•á‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§á‡§®‡§¨‡•â‡§ï‡•ç‡§∏ ‡§™‡§∞ ‡§®‡§ú‡§º‡§∞ ‡§∞‡§ñ‡•á‡§Ç ‡§î‡§∞ ‡§â‡§∏ ‡§¶‡§ø‡§® ‡§ï‡•á ‡§Ö‡§Ç‡§§ ‡§§‡§ï ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§≠‡§æ‡§ó‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§á‡§∏ ‡§á‡§Ç‡§ü‡§∞‡•ç‡§®‡§∂‡§ø‡§™ ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§Ü‡§™‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§ï‡§æ‡§Æ ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§Ç‡§§‡§ú‡§æ‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á! ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à, ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø‡§ï ‡§ú‡•Ä‡§è‡§®‡§è‡§Ü‡§à ‡§á‡§Ç‡§ü‡§∞‡•ç‡§®‡§∂‡§ø‡§™ ‡§ü‡•Ä‡§Æ'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373afc4-5388-41b7-98d3-69e24d3d8b57",
   "metadata": {},
   "source": [
    "### **Understanding Language‚ÄìScript Codes in Multilingual AI Systems**\n",
    "\n",
    "When working with multilingual NLP and Generative AI systems, you will often encounter language identifiers such as:\n",
    "\n",
    "* `hin_Deva`\n",
    "* `kan_Knda`\n",
    "* `kas_Arab`\n",
    "* `kas_Deva`\n",
    "* `eng_Latn`\n",
    "\n",
    "These identifiers follow a standard and production-friendly convention that helps AI systems correctly interpret how a language is written.\n",
    "\n",
    "> **Important:**\n",
    "> To explore additional supported languages and codes, refer to the official FLORES+ language coverage page hosted on\n",
    "> **Hugging Face**:\n",
    "> [https://huggingface.co/datasets/openlanguagedata/flores_plus#language-coverage](https://huggingface.co/datasets/openlanguagedata/flores_plus#language-coverage)\n",
    "\n",
    "#### **Language_Script Code Format**\n",
    "\n",
    "All such identifiers follow the same structure:\n",
    "\n",
    "```text\n",
    "<language>_<script>\n",
    "```\n",
    "\n",
    "* The **language** part specifies the language.\n",
    "* The **script** part specifies the writing system used for that language.\n",
    "\n",
    "This distinction is critical in real-world multilingual and GenAI pipelines.\n",
    "\n",
    "#### **Why Script Matters?**\n",
    "\n",
    "The `script` tells us **how a particular language is written**.\n",
    "\n",
    "For example, consider the following two sentences:\n",
    "\n",
    "```text\n",
    "‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§ö‡§æ‡§π‡§ø‡§è\n",
    "```\n",
    "\n",
    "```text\n",
    "mujhe kitaab chahiye\n",
    "```\n",
    "\n",
    "Both sentences are in **Hindi**, but:\n",
    "* the first is written in **Devanagari script** (`Deva`)\n",
    "* the second is written in **Latin script** (`Latn`)\n",
    "\n",
    "So, conceptually:\n",
    "* `hin_Deva` ‚Üí Hindi written in Devanagari\n",
    "* `hin_Latn` ‚Üí Hindi written in Latin characters (romanized form)\n",
    "\n",
    "#### **How the Model Sees This Difference?**\n",
    "\n",
    "From the model‚Äôs point of view:\n",
    "* the **character set is completely different**\n",
    "* the **token IDs are completely different**\n",
    "* the **subword segmentation is completely different**\n",
    "\n",
    "Even though humans perceive both examples as the same language, the model treats them as very different inputs.\n",
    "\n",
    "#### **Common Script Codes**\n",
    "\n",
    "| Script code | Meaning        | Writing system                                                     |\n",
    "| ----------- | -------------- | ------------------------------------------------------------------ |\n",
    "| **Deva**    | Devanagari     | Used for Hindi, Marathi, Sanskrit, Nepali, etc.                    |\n",
    "| **Knda**    | Kannada script | Used for the Kannada language                                      |\n",
    "| **Arab**    | Arabic script  | Used for Arabic, Urdu, Kashmiri (one form), Persian, etc.          |\n",
    "| **Latn**    | Latin script   | Used for English, French, Spanish, German and many other languages |\n",
    "\n",
    "#### **Codes for Indian Languages**\n",
    "\n",
    "| Language  | FLORES Code | Script     | Notes                        |\n",
    "| --------- | ----------- | ---------- | ---------------------------- |\n",
    "| Hindi     | hin_Deva    | Devanagari | Standard Hindi writing       |\n",
    "| Bengali   | ben_Beng    | Bengali    | Used for Bangla              |\n",
    "| Tamil     | tam_Taml    | Tamil      | Native Tamil script          |\n",
    "| Telugu    | tel_Telu    | Telugu     | Native Telugu script         |\n",
    "| Marathi   | mar_Deva    | Devanagari | Same script as Hindi         |\n",
    "| Gujarati  | guj_Gujr    | Gujarati   | Native Gujarati script       |\n",
    "| Kannada   | kan_Knda    | Kannada    | Native Kannada script        |\n",
    "| Malayalam | mal_Mlym    | Malayalam  | Native Malayalam script      |\n",
    "| Punjabi   | pan_Guru    | Gurmukhi   | Punjabi (India)              |\n",
    "| Odia      | ory_Orya    | Odia       | Earlier called Oriya         |\n",
    "| Assamese  | asm_Beng    | Bengali    | Assamese uses Bengali script |\n",
    "| Urdu      | urd_Arab    | Arabic     | Perso-Arabic script          |\n",
    "| Kashmiri  | kas_Arab    | Arabic     | Common in Kashmir            |\n",
    "| Kashmiri  | kas_Deva    | Devanagari | Alternate script             |\n",
    "| Nepali    | nep_Deva    | Devanagari | Same script family as Hindi  |\n",
    "| Sindhi    | snd_Arab    | Arabic     | Common form                  |\n",
    "| Sindhi    | snd_Deva    | Devanagari | Alternate form               |\n",
    "| Sanskrit  | san_Deva    | Devanagari | Classical usage              |\n",
    "\n",
    "\n",
    "#### **Codes for Popular International Languages**\n",
    "\n",
    "| Language              | FLORES Code | Script            | Notes                  |\n",
    "| --------------------- | ----------- | ----------------- | ---------------------- |\n",
    "| English               | eng_Latn    | Latin             | Global default         |\n",
    "| Spanish               | spa_Latn    | Latin             |                        |\n",
    "| French                | fra_Latn    | Latin             |                        |\n",
    "| German                | deu_Latn    | Latin             |                        |\n",
    "| Portuguese            | por_Latn    | Latin             |                        |\n",
    "| Italian               | ita_Latn    | Latin             |                        |\n",
    "| Russian               | rus_Cyrl    | Cyrillic          |                        |\n",
    "| Arabic                | arb_Arab    | Arabic            | Modern Standard Arabic |\n",
    "| Chinese (Simplified)  | zho_Hans    | Han (Simplified)  | Mainland China usage   |\n",
    "| Chinese (Traditional) | zho_Hant    | Han (Traditional) | Taiwan / HK usage      |\n",
    "| Japanese              | jpn_Jpan    | Japanese          | Mixed writing system   |\n",
    "| Korean                | kor_Hang    | Hangul            |                        |\n",
    "| Turkish               | tur_Latn    | Latin             |                        |\n",
    "| Indonesian            | ind_Latn    | Latin             |                        |\n",
    "| Vietnamese            | vie_Latn    | Latin             |                        |\n",
    "| Thai                  | tha_Thai    | Thai              |                        |\n",
    "| Hebrew                | heb_Hebr    | Hebrew            |                        |\n",
    "\n",
    "#### **Key Takeaway**\n",
    "In modern multilingual AI systems, a language is **not uniquely identified by its language name alone**.\n",
    "Instead, it is defined as:\n",
    "```text\n",
    "(language, script)\n",
    "```\n",
    "This is why:\n",
    "```\n",
    "kas_Arab  ‚â†  kas_Deva\n",
    "hin_Deva  ‚â†  eng_Latn\n",
    "```\n",
    "Even when the spoken language may be the same, the writing system directly affects tokenization, embeddings, retrieval quality, and model behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750211f-c82f-421c-ab4d-7c118f4ffea6",
   "metadata": {},
   "source": [
    "## **Question Answering**\n",
    "\n",
    "### **What's QA Model?**\n",
    "Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65409cd9-fb80-43a4-abe0-865820c28318",
   "metadata": {},
   "source": [
    "### **Example Usage - QA Task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66df60c-1ff0-49fe-ac90-4e2933b14780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372c655241e24e4780b1c88a5478459e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d53eb6fec48afa17510938add715e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0775f975694a1da204049d7cbda4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1ca8dc47c94621a203adfd6515d34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c6d026b6584372b16b907c73dafe76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa95b4447594312aa2c428285e3b902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the inference task\n",
    "reader = pipeline(\n",
    "    task=\"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e13acf-412f-4514-8208-f7a87d7117c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.7018205523490906,\n",
       " 'start': 418,\n",
       " 'end': 436,\n",
       " 'answer': '20th of this month'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"When is the Offer Letter going to be shared?\"\n",
    "\n",
    "reader(question=question, context=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf57423c-f7da-4788-b0ae-59a21086a128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9124733209609985,\n",
       " 'start': 203,\n",
       " 'end': 221,\n",
       " 'answer': '25th of this month'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"When is internship starting?\"\n",
    "\n",
    "reader(question=question, context=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b976ff-e3f3-4d31-9fe0-70ba9d50c80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.7776859402656555,\n",
       " 'start': 27,\n",
       " 'end': 43,\n",
       " 'answer': 'Flipkart website'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "question = \"Where did the customer buy the product?\"\n",
    "\n",
    "reader(question=question, context=product_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59fa1f3-62cf-4983-b5af-22d83e5d5f0f",
   "metadata": {},
   "source": [
    "## **Text Generation**\n",
    "\n",
    "Generating text is the task of generating new text given another text. These models can, for example, fill in incomplete text or paraphrase. A Text Generation model is also known as a **causal language model**.\n",
    "\n",
    "**Usecases**\n",
    "- **Instruction Models:** Some of the most powerful instruction-tuned open-access models like Mixtral 8x7B, Cohere Command R+, and Meta Llama3 70B.\n",
    "- **Code Generation:** One of the most popular open-source models for code generation is StarCoder, which can generate code in 80+ languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e225623-7aac-46f9-a1f3-de9d92bbbfa6",
   "metadata": {},
   "source": [
    "### **Example Usage - Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fea4f42-f770-4476-8fac-17d050ea84f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39c750a6070480eadb20220772ec846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e864c3435a94599a13c41ed5c3d2c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0923b9fe704c63a7e05b1a5a3345d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0192afb1684d0ca0c57ea9ba172f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a4d1dcc5d34ebc97ff177e578646bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3b70515cdf44a9ac0a98f42d990034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e4e60ed1b84dc0b9ea97024e5fc84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c26ee0a-f885-4282-8c96-7ff9ce979508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant. Can you help me write the response for the following product review:\n",
      "### PRODUCT REVIEW ###\n",
      "I bought this product from Flipkart website.\n",
      "This product is very worst and replacement policy is very bad. Even I went to their New Delhi support center.\n",
      "I used this laptop only for 30 minute and suddenly it turn off and it will never turn on.\n",
      "And Flipkart website does not replace this product. I should have gone for better brands like Apple or Alienware.\n",
      "\n",
      "### CUSTOMER SERVICE RESPONSE ###\n",
      "Dear Customer, I am sorry to hear this. Please be assured that \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"You are a helpful AI assistant. Can you help me write the response for the following product review:\n",
    "### PRODUCT REVIEW ###\n",
    "{product_review}\n",
    "\n",
    "### CUSTOMER SERVICE RESPONSE ###\n",
    "Dear Customer, I am sorry to hear this. Please be assured that \n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb3b262-35aa-4531-8de5-13888cdba6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'You are a helpful AI assistant. Can you help me write the response for the following product review:\\n### PRODUCT REVIEW ###\\nI bought this product from Flipkart website.\\nThis product is very worst and replacement policy is very bad. Even I went to their New Delhi support center.\\nI used this laptop only for 30 minute and suddenly it turn off and it will never turn on.\\nAnd Flipkart website does not replace this product. I should have gone for better brands like Apple or Alienware.\\n\\n### CUSTOMER SERVICE RESPONSE ###\\nDear Customer, I am sorry to hear this. Please be assured that \\nwe take all the issues that you have with our products. If you have any further questions, please feel free to reach out to our customer support team. \\n\\nThank you for your patience and for taking the time to reach out.\\n### \\n\\n### RECOMMENDATIONS \\nI recommend that users should check the product description and warranty information before purchasing. \\n\\n### \\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n### \\n\\n### \\n### \\n'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "response = generator(prompt, max_length=200)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "981fd239-0ca5-4752-aa9f-72232711cd90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant. Can you help me write the response for the following product review:\n",
      "### PRODUCT REVIEW ###\n",
      "I bought this product from Flipkart website.\n",
      "This product is very worst and replacement policy is very bad. Even I went to their New Delhi support center.\n",
      "I used this laptop only for 30 minute and suddenly it turn off and it will never turn on.\n",
      "And Flipkart website does not replace this product. I should have gone for better brands like Apple or Alienware.\n",
      "\n",
      "### CUSTOMER SERVICE RESPONSE ###\n",
      "Dear Customer, I am sorry to hear this. Please be assured that \n",
      "we take all the issues that you have with our products. If you have any further questions, please feel free to reach out to our customer support team. \n",
      "\n",
      "Thank you for your patience and for taking the time to reach out.\n",
      "### \n",
      "\n",
      "### RECOMMENDATIONS \n",
      "I recommend that users should check the product description and warranty information before purchasing. \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "### \n",
      "\n",
      "### \n",
      "### \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46a674-1f71-4194-b2d1-bb2718d0e389",
   "metadata": {},
   "source": [
    "## **Fill-Mask**\n",
    "\n",
    "### **What is Fill-Mask Task?**\n",
    "Masked language modeling (i.e. Fill-Mask) is the task of masking some of the words in a sentence and predicting which words should replace those masks. These models are useful when we want to get a statistical understanding of the language in which the model is trained in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f91b833-3a5c-4ae2-bb85-1b6d61538bd6",
   "metadata": {},
   "source": [
    "### **Example Usage - Fill-Mask Task**\n",
    "Use Cases: Correcting the misprinted words in a book, guessing the lost words from the ancient manuscripts, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e508958e-95e5-4a8c-87f7-4cf9bb7a89a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Specify the inference task\n",
    "unmasker = pipeline(\n",
    "    task='fill-mask',\n",
    "    model=\"google-bert/bert-base-uncased\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51110399-3e8b-4419-a76c-bf5727f0959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.318359375,\n",
       "  'token': 2064,\n",
       "  'token_str': 'can',\n",
       "  'sequence': 'artificial intelligence can take over the world.'},\n",
       " {'score': 0.1806640625,\n",
       "  'token': 2097,\n",
       "  'token_str': 'will',\n",
       "  'sequence': 'artificial intelligence will take over the world.'},\n",
       " {'score': 0.058837890625,\n",
       "  'token': 2000,\n",
       "  'token_str': 'to',\n",
       "  'sequence': 'artificial intelligence to take over the world.'},\n",
       " {'score': 0.0458984375,\n",
       "  'token': 2052,\n",
       "  'token_str': 'would',\n",
       "  'sequence': 'artificial intelligence would take over the world.'},\n",
       " {'score': 0.0458984375,\n",
       "  'token': 2015,\n",
       "  'token_str': '##s',\n",
       "  'sequence': 'artificial intelligences take over the world.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the input to the pipeline\n",
    "unmasker(\"Artificial Intelligence [MASK] take over the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c902c2-7ded-46ea-9731-e9e6d4a1440e",
   "metadata": {},
   "source": [
    "## **Feature Extraction**\n",
    "\n",
    "### **What is Feature Extraction Task?**\n",
    "Feature extraction is the task of extracting features learnt in a model. This process is also known as **Vectorization/Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9db34-d671-4439-a72f-71757c7a1fce",
   "metadata": {},
   "source": [
    "### **Example Usage - Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2dadbd-2128-4cd4-945f-199227f0641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the feature extraction pipeline and model\n",
    "pipe = pipeline(\n",
    "    task=\"feature-extraction\",\n",
    "    model=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c459ae8-e467-4569-82d1-1bfe9a187dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get embeddings\n",
    "embedding = pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5409db2-6486-40cf-a4a7-623a939c143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is a list with one item per sentence\n",
    "sentence_embeddings = embedding[0][0][0:10]\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843e4a2-0a88-42bb-a2ed-855dab1433ba",
   "metadata": {},
   "source": [
    "## **Sentence Similarity**\n",
    "\n",
    "### **What is Sentence Similarity?**\n",
    "Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping.\n",
    "\n",
    "### **Installing sentence-transformers**\n",
    "The Sentence Transformers library is very powerful for calculating embeddings of sentences, paragraphs, and entire documents. An embedding is just a vector representation of a text and is useful for finding how similar two texts are.\n",
    "\n",
    "```\n",
    "! pip install -U sentence-transformers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17397f0c-2ca9-4ffe-a82d-952b4cb72e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc03f1-9784-4e88-b6d3-8e1e6da3f166",
   "metadata": {},
   "source": [
    "### **Example Usage - Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f852f56c-9fcb-41bf-8c94-d89ef2817778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611c20e53d0e459cbb379b5e09f44fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d80c294eff745aabc6834867eff230d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d249b4f649db4ccd9da7782004a18522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a8ed4e166049bb9b1c6640a9e0710d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b85d93c10df471b8e7a914d4ea54e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c725e7223cd4e80827770ebf87e9200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a7fd40c9c34934aac2f3cfa3ef5340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24427a2e00ec403aba926c7396a5b6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afe3affa0484ec38bcec31fad5c4558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddc00dc37434dbaa861d8faa9686844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a279faf57cec4942941615e4d721bb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eee0851-118b-4d99-bcc0-5114506a2c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0432431 ,  0.007915  ,  0.02221592, ...,  0.00474837,\n",
       "         0.08790506,  0.03770212],\n",
       "       [-0.06636767,  0.0239995 ,  0.00552235, ...,  0.00689973,\n",
       "        -0.03125972,  0.03236982],\n",
       "       [-0.05473284,  0.03603868, -0.03761066, ...,  0.00829173,\n",
       "         0.04758519,  0.03967499],\n",
       "       ...,\n",
       "       [ 0.0090486 , -0.04935008, -0.03463788, ...,  0.0069707 ,\n",
       "         0.00719365,  0.07223017],\n",
       "       [-0.00118566, -0.00170601,  0.04594418, ..., -0.01025474,\n",
       "         0.10647611, -0.03625185],\n",
       "       [ 0.04819277, -0.13161905, -0.03929338, ...,  0.05015412,\n",
       "         0.02368984, -0.06484961]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    \"Apples - High in fiber, support digestion, and promote heart health.\",\n",
    "    \"Bananas - Rich in potassium, help regulate blood pressure and muscle function.\",\n",
    "    \"Oranges - Packed with vitamin C, boost immunity, and promote skin health.\",\n",
    "    \"Blueberries - High in antioxidants, improve brain function and reduce inflammation.\",\n",
    "    \"Strawberries - Support heart health and contain anti-aging antioxidants.\",\n",
    "    \"Watermelon - Hydrating fruit with lycopene, good for heart and skin health.\",\n",
    "    \"Pineapple - Contains bromelain, aids digestion, and reduces inflammation.\",\n",
    "    \"Avocado - Loaded with healthy fats, supports brain and heart health.\",\n",
    "    \"Papaya - Rich in enzymes for digestion and boosts skin health.\",\n",
    "    \"Pomegranate - Full of antioxidants, improves blood circulation, and heart health.\",\n",
    "    \"Carrots - High in beta-carotene, improve eye health and skin glow.\",\n",
    "    \"Spinach - Rich in iron, good for blood health and energy levels.\",\n",
    "    \"Broccoli - Contains sulforaphane, which has anti-cancer properties.\",\n",
    "    \"Tomatoes - Packed with lycopene, supports heart health and skin protection.\",\n",
    "    \"Bell Peppers - High in vitamin C, boosts immunity, and reduces inflammation.\",\n",
    "    \"Cucumber - Hydrating vegetable, aids in digestion, and supports skin health.\",\n",
    "    \"Garlic - Has antibacterial properties, supports heart health and immunity.\",\n",
    "    \"Ginger - Anti-inflammatory, helps with digestion and nausea relief.\",\n",
    "    \"Beets - Improve blood flow, support endurance, and detox the liver.\",\n",
    "    \"Sweet Potatoes - Rich in fiber and vitamin A, supports vision and digestion.\"\n",
    "]\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Computing embeddings for the dataset\n",
    "data_embeddings = model.encode(\n",
    "    data,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "data_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a10d9c-3213-4739-966f-f4e41669f443",
   "metadata": {},
   "source": [
    "### **Calculating Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4cc097-3f42-40f6-9b8e-4f49e1d31328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.77969360e-02, -1.30056413e-02, -1.58315280e-03,  6.25351071e-02,\n",
       "       -9.57588141e-04,  4.90093194e-02,  1.67138968e-02,  2.11121961e-02,\n",
       "        3.18224095e-02, -2.74740485e-03,  7.46253179e-03,  7.31462985e-03,\n",
       "        1.43662486e-02, -5.87841123e-03, -3.72029445e-03,  4.27569821e-02,\n",
       "        3.76452096e-02,  6.18550554e-02,  5.34261926e-04, -1.20859131e-01,\n",
       "       -4.11252771e-03,  2.53534131e-02,  2.24291664e-02,  4.50075837e-03,\n",
       "       -3.97906043e-02, -8.67136866e-02,  6.52504265e-02, -2.09393185e-02,\n",
       "       -7.12348521e-02, -7.58382753e-02,  1.52243190e-02, -2.08580196e-02,\n",
       "        1.14972107e-01,  1.42562622e-02, -7.50390589e-02, -4.60609645e-02,\n",
       "        7.01426864e-02, -5.20316511e-02,  2.21953797e-03, -7.68518671e-02,\n",
       "       -2.00004157e-04,  7.40764514e-02,  3.65690663e-02, -5.87832257e-02,\n",
       "        3.47544253e-03, -2.50390917e-02, -3.77727766e-03,  2.30258536e-02,\n",
       "        6.32770211e-02,  2.04979144e-02, -1.02413327e-01, -3.03632300e-02,\n",
       "       -6.11401908e-02, -1.34097822e-02,  4.48253676e-02,  1.24897435e-02,\n",
       "       -5.54256774e-02, -5.96432500e-02, -1.05540408e-02,  3.05118486e-02,\n",
       "        3.31028812e-02, -1.16932295e-01,  2.61755232e-02, -6.32119225e-03,\n",
       "       -2.69268919e-02, -6.88386932e-02, -3.53153087e-02,  4.25551422e-02,\n",
       "        1.97312864e-03,  2.69041061e-02, -7.64562711e-02,  1.04426881e-02,\n",
       "        3.82747427e-02,  1.30571621e-02, -7.04374611e-02,  5.58545478e-02,\n",
       "        4.93224896e-03, -7.94743598e-02, -6.06725775e-02,  2.66316216e-02,\n",
       "        3.20997313e-02,  6.39002845e-02,  1.36014940e-02,  7.64383450e-02,\n",
       "        4.52171192e-02,  1.35450307e-02, -1.48446290e-02,  4.25740555e-02,\n",
       "       -7.60518163e-02,  1.02457069e-01,  4.10791002e-02,  9.22740530e-03,\n",
       "        4.52722535e-02,  2.52924971e-02, -3.71010154e-02, -6.22031465e-02,\n",
       "        1.12932520e-02, -1.07202716e-01, -6.76314011e-02,  1.08013367e-02,\n",
       "       -7.08086491e-02, -3.85806672e-02,  2.04145182e-02, -7.26116821e-02,\n",
       "       -7.15013742e-02,  2.24801302e-02, -7.81696581e-04, -6.51623681e-02,\n",
       "        4.93200235e-02,  6.50559664e-02,  6.14590272e-02,  9.53382533e-03,\n",
       "       -6.67982623e-02, -9.13530122e-03, -9.37886462e-02,  6.02378398e-02,\n",
       "        9.17831883e-02, -1.69862099e-02, -4.01897840e-02,  4.82508913e-02,\n",
       "       -4.47880477e-02, -7.14111328e-03,  2.08005030e-02, -1.71802565e-02,\n",
       "        1.55352764e-02, -2.39265338e-03,  1.36624807e-02, -1.91234729e-33,\n",
       "       -2.60210857e-02, -2.75658891e-02,  2.45777350e-02,  1.81082007e-03,\n",
       "        9.00779665e-02,  1.77003406e-02, -1.33813936e-02,  7.25481543e-04,\n",
       "        1.35183066e-01, -7.78724328e-02, -9.40591916e-02, -3.55354510e-02,\n",
       "        2.36224551e-02,  1.03045441e-02, -5.42126503e-03, -3.88650671e-02,\n",
       "       -8.51610601e-02,  2.42470875e-02, -2.80821342e-02, -4.03380068e-03,\n",
       "       -2.77198516e-02, -6.61970451e-02, -2.32764184e-02, -5.60668856e-02,\n",
       "       -5.67833101e-03, -5.28230816e-02,  3.31761129e-02, -2.54257414e-02,\n",
       "        9.83363539e-02, -2.69835796e-02,  1.22918384e-02, -4.35950123e-02,\n",
       "        2.73306621e-03,  2.71460265e-02, -2.16840710e-02,  3.46274748e-02,\n",
       "       -3.79156731e-02, -2.16180421e-02, -9.59792081e-03,  4.09726128e-02,\n",
       "        1.72291398e-02, -5.06320316e-03,  2.12109108e-02,  5.18015772e-02,\n",
       "        1.93895809e-02, -1.26061216e-01, -6.06572330e-02,  5.49101308e-02,\n",
       "       -1.03792222e-02,  3.69339176e-02,  1.02402046e-02, -4.16049443e-04,\n",
       "        3.77804637e-02, -6.76679909e-02, -4.24168631e-02, -7.45805874e-02,\n",
       "        1.85117649e-03,  2.11166125e-02,  7.73578067e-04,  5.08820219e-03,\n",
       "       -3.40488814e-02, -1.29202241e-02, -2.14982009e-03, -2.89379805e-03,\n",
       "       -4.17745374e-02,  1.01706900e-01, -8.63212869e-02, -8.17670822e-02,\n",
       "       -5.43206185e-02,  3.40850987e-02,  1.31657859e-02, -3.08309738e-02,\n",
       "        1.05154335e-01,  3.70499752e-02, -6.31766617e-02, -3.20276655e-02,\n",
       "       -1.21832611e-02,  2.66923085e-02, -3.20683084e-02,  8.36554244e-02,\n",
       "       -8.61120373e-02, -1.41885038e-02, -1.60239283e-02,  1.31290108e-01,\n",
       "       -7.07856864e-02,  7.02868402e-02, -1.00504145e-01,  1.40870521e-02,\n",
       "        1.77800655e-01, -5.87902963e-02, -5.98031841e-02,  1.11776730e-02,\n",
       "       -4.81079109e-02,  7.33064488e-02, -1.88743826e-02,  1.39715861e-33,\n",
       "        4.29112464e-02, -6.82818294e-02,  2.53313966e-02,  1.04206137e-01,\n",
       "        6.30427450e-02,  1.74103286e-02,  1.29899569e-02, -2.82415678e-03,\n",
       "        2.33856924e-02, -7.80679062e-02, -1.07813068e-02,  1.84667092e-02,\n",
       "       -8.26125592e-03, -3.08657177e-02,  7.90436789e-02,  8.82566646e-02,\n",
       "        6.42921105e-02,  5.43487407e-02, -6.34084567e-02,  2.04734541e-02,\n",
       "       -8.32558498e-02,  1.12856634e-01,  2.60605924e-02, -1.09441932e-02,\n",
       "        7.48991594e-02,  4.63758931e-02,  2.48661321e-02, -4.61105034e-02,\n",
       "       -2.18207967e-02,  5.57470396e-02,  7.16859996e-02,  3.93810980e-02,\n",
       "       -5.56836240e-02, -2.53463034e-02, -3.42632690e-03,  3.06434967e-02,\n",
       "       -3.48360352e-02, -7.06183538e-02, -5.48368096e-02,  1.19282149e-01,\n",
       "        2.33082678e-02,  2.21961513e-02,  2.61154436e-02,  1.33704185e-01,\n",
       "       -1.44744024e-03,  2.89936345e-02,  2.41213338e-03, -8.11554119e-03,\n",
       "        5.94930016e-02,  1.55777233e-02, -8.26395862e-03,  4.32447204e-03,\n",
       "       -2.24652681e-02,  1.81949642e-02,  1.15786791e-01, -6.21520588e-03,\n",
       "        1.18962396e-02, -7.01191649e-02, -9.61696208e-02, -6.02907389e-02,\n",
       "       -9.99779403e-02, -1.00718616e-02,  4.99435514e-02, -5.64308353e-02,\n",
       "        3.87422293e-02,  7.87848160e-02, -2.40412503e-02,  2.01523732e-02,\n",
       "       -7.45450258e-02, -2.32827775e-02,  6.20245934e-02,  3.27005819e-03,\n",
       "        3.36410920e-03,  3.37892100e-02, -1.74694508e-02,  6.61557391e-02,\n",
       "       -2.88231327e-04,  1.17315998e-04, -5.37740961e-02,  7.79175982e-02,\n",
       "       -8.92177299e-02,  3.04027051e-02, -6.64153695e-02, -4.14436013e-02,\n",
       "        6.38484815e-03,  2.29040179e-02, -1.00085497e-01,  3.16635780e-02,\n",
       "       -4.34320383e-02,  1.12393163e-01,  4.63960599e-03, -2.32132785e-02,\n",
       "        1.00222668e-02, -3.40611674e-02,  2.72010062e-02, -1.52883555e-08,\n",
       "        1.04081437e-01, -8.46538842e-02, -2.75979824e-02,  3.61889564e-02,\n",
       "       -2.24745739e-02, -3.07311444e-03, -6.07301742e-02,  5.91569208e-02,\n",
       "        4.31229547e-02, -1.77270193e-02, -2.92148683e-02,  3.16941589e-02,\n",
       "        2.79252953e-03,  7.59560764e-02, -5.39014302e-03, -3.45296524e-02,\n",
       "        4.68260236e-02,  3.87495384e-02, -5.92903495e-02,  3.61620449e-02,\n",
       "       -1.37427464e-01,  1.83246452e-02, -7.85034135e-05, -4.25424166e-02,\n",
       "        3.32184769e-02, -2.78778076e-02,  2.95696617e-03, -1.96248833e-02,\n",
       "        3.96726802e-02, -3.77364941e-02,  2.22913101e-02,  2.12863218e-02,\n",
       "       -1.69288367e-02, -1.15354694e-02,  5.89141669e-03, -1.23570729e-02,\n",
       "        1.21445440e-01,  1.22637479e-02, -6.88165575e-02, -2.06939224e-03,\n",
       "       -4.48353449e-03, -8.43930244e-03, -1.44447442e-02, -6.56150572e-04,\n",
       "       -3.31478566e-02, -4.79748137e-02,  1.11687472e-02,  3.92175205e-02,\n",
       "       -2.25346405e-02,  2.08067577e-02, -1.87710319e-02,  2.47931853e-02,\n",
       "        8.51281881e-02,  5.99629730e-02,  1.45237250e-02,  1.18240872e-02,\n",
       "        3.90059538e-02, -6.64029792e-02,  7.63899041e-03,  3.03381979e-02,\n",
       "        3.68933491e-02, -1.79286697e-03,  9.75351855e-02,  4.09147004e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which fruit is good for digestion and reduces inflammation?\"\n",
    "\n",
    "query_embedding = model.encode(\n",
    "    query,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e54b4d5-f38f-47ea-a42b-8e6e1158cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6068, 0.4714, 0.5217, 0.5700, 0.5221, 0.5584, 0.6845, 0.4721, 0.5069,\n",
      "         0.4233, 0.3236, 0.4451, 0.4094, 0.4368, 0.4153, 0.4201, 0.3507, 0.5387,\n",
      "         0.3945, 0.4669]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "cosine_scores = util.cos_sim(query_embedding, data_embeddings)\n",
    "\n",
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de9c57b-62f6-4ab8-89b0-4403922649b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best match:\n",
      "Pineapple - Contains bromelain, aids digestion, and reduces inflammation.\n",
      "Score: 0.6845415830612183\n"
     ]
    }
   ],
   "source": [
    "# Get best match\n",
    "best_idx = int(cosine_scores.argmax())\n",
    "\n",
    "print(\"\\nBest match:\")\n",
    "print(data[best_idx])\n",
    "print(\"Score:\", float(cosine_scores[0][best_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
